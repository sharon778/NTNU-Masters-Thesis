%===================================== CHAP 2 =================================

\chapter{Literary Review}
\textbf{Introduction}
\\
Recent advances in deep learning may render several state-of-the-art approaches within other fields of artificial intelligence (AI) such as image classification and natural language processing obsolete, as they have been outperformed by more generally applicable algorithms of deep learning (\cite{LeCun2015, Schmidhuber2014}). These advances are due to both computational as well as algorithmic improvements within the field. New insights into how high-level cognition may be constituted and emerge in neural networks may further advance field's capabilities, possibly beyond what can be achieved only by an increase in computational power. At the very core of such new insights lies the symbol grounding problem. This problem is addressed by several authors such as \cite{Yamashita2008, Tani2014}, who propose solutions to the long standing symbol grounding problem. However, there are still issues present in the models related to generalisation. The problem of generalisation has on the other hand been addressed by other authors such as \cite{McClelland1995}, and more recently \cite{Hattori2014}. In their seminal paper, \cite{McClelland1995} propose a dual-network memory model, hypothesising that the brain solves the problem of long-term memory and memory consolidation by the use of a dual-network memory architecture. Because the body of research, to the best of our knowledge, on the dual-network memory architecture is fairly limited, the goal of this thesis is to further investigate the issues of catastrophic forgetting and generalisation, memory, and high-level cognition in such an architecture. Elucidating high-level abstraction in this architecture could provide key insights for further advances within deep learning, artificial intelligence, neuroscience and psychology. The problem of catastrophic forgetting is of central importance to memory formation in neural networks, and thus also plays a key role in forming abstract memories from different types of memories. We wish to investigate it outside of the domain of traditional topologies, as well as the standard feed-forward back-propagate algorithm. Furthermore, building on the work of \cite{Hattori2014}, we seek to embed an approach such as multiple-timescales recurrent neural networks in a dual-network memory model. The motivation for this stems from seeking to attain an artificial neural network model capable of attaining high-level cognitive behaviour as well as integration across abstract memories.
In order to investigate the body of research on the topic, the databases of Scopus, Web of Science, IEEE, Nature, and arXiv were used to locate references of interest. A process of following networks of citations was employed, particularly by using the paper of \cite{McClelland1995}. Furthermore, as some heavily cited authors appeared, such as Tani and Schmidhuber, their list of publications were used as sources for references, using Google's search engine to find their lists of publications.
\\
\\
\textbf{French, R. M. (1992). Semi-distributed Representations and Catastrophic Forgetting in Connectionist Networks. Connection Science, 4(3-4), 365-377.}

\cite{French1992} addresses the problem of catastrophic forgetting \cite{McCloskey1989, Ratcliff1990} in neural networks that are trained using feed-forward back-propagation, and argues that it occurs because of representational overlap. A method alleviating the problem is to make use of a sparse distributed memory (SDM), which works fairly well until the memory is digested. However, once it is digested - even more catastrophic forgetting occurs, as nothing new can be learned either. Furthermore, in using an SDM it may be impossible to combine old high-level representations with new ones, and thus the approach remains less generalisable. As for semi-distributedness of representations, because they are more constricted to local interactions, they will also fail to generalise beyond a certain extent. One way of viewing this is that the distributedness manages to segment more tasks due to a kind of regularizer that constrains the state space. However, the simplification may oversimplify the model, causing it to lose out on crucial information due to locally constrained pattern formations. The author's proposed solution to combine the best of both worlds is node sharpening. Node sharpening locally constrains input patterns to enhance the most prominent features of the input, effectively resulting in sparse representations, as less "noise" is propagated throughout the network, and the most principal input nodes being in focus. This does indeed alleviate catastrophic forgetting, but it does so by performing a trade-off between generalisation and not forgetting. Although catastrophic forgetting may be biologically plausible, the mechanism with which the networks are trained; feed-forward back-propagate, as well as the topologies employed, remains biologically implausible. Furthermore, today's state-of-the-art algorithms employs other transfer functions, network topologies and other ways of doing gradient descent - if doing gradient descent at all. Therefore, the claim that the trade-off between catastrophic forgetting and generalisation is inevitable, may not hold today.
\\
\\
\textbf{French, R. M. (1994). Dynamically constraining connectionist networks to produce distributed, orthogonal representations to reduce catastrophic interference. Network, 1111, 00001.}

Building on his former work (\cite{French1992}), \cite{French1994} proposes a model which dynamically sharpens the most relevant input nodes. Once two different outputs has been presented to a standard feed-forward back-propagate (FFBP) network, a context bias is calculated in the hidden layer and propagated back to the input layer. Shortly put, this emphasizes the differences of the distinct categories, focusing on segmenting and orthogonalizing on the most prominent properties of difference. Thus a more orthogonal, well distributed pattern is learned.
Although this type of segmentation works well, it is still very similar to the former approach in \cite{French1992}, and suffers from the same trade-off between remembering and generalisation. As in other FFBP networks performing gradient descent in the weight space (\cite{Hinton1989}), it will only find the most principal components, scaling with how much information the network is able to store (mainly relative to its size). Thus when it fails to attain a sufficient accuracy for a given task, the detailed information which is ignored could have been used in the segmentation process (in the case of categorisation). Furthermore, it may be the case that only finding the most principal correlations of the distribution does not reveal the true nature of the categories, failing to extract the most precise categorical correlations or properties. This is at the very core of the sensitivity-stability dilemma \cite{Hebb1949}. One way way of addressing this dilemma is by multi-network systems , which \cite{French1994} suggests in his conclusion. This may produce refined solutions and abstractions and more sophisticated pattern-associations, although seemingly less computationally efficient.
\\
\\
\textbf{McClelland, J. L., McNaughton, B. L., \& O’Reilly, R. C. (1995). Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory. Psychological Review, 102(3), 419-457.}

In this seminal paper, \cite{McClelland1995} propose a memory model of the brain in which the hippocampus is responsible for the consolidation of memories to the neocortex, with the neocortex storing the semantic and episodic memory. The synthesis of recall from the deeper layers of the neocortex and representations in the working memory itself enables contexts to be distinguished or connected. The learning and consolidation to the neocortex is essentially performed in an interleaved fashion; slowly potentiating and instantiating those memories to the cortex. Thus we have a bottom-up and top-down synthesis where recall is combined with novel patterns in the hippocampal module. This raises the question of how such an interconnectedness is constituted both topologically and in terms of local information-processing. Furthermore, the question is whether principles from outside the neocortex and hippocampus need to be extracted and implemented to successfully have this functionality emerge in computational models. Addressing the latter, the proposed model suggests that the hippocampus and neocortex constitute the mechanisms for successful integration across memories, as well as keeping memories fairly intact. The specifics on how these mechanisms are constituted, however, remains obscure or undiscovered.
\\
\\
\textbf{French, R. M. (1997). Pseudo-recurrent Connectionist Networks: An Approach to the “Sensitivity-Stability” Dilemma. Connection Science, 9(4), 353-380.}

The authors present a series of experiments that address the sensitivity-stability (\cite{Hebb1949}), or the stability-plasticity (\cite{Carpenter1987}) problem. They show that a pseudo-recurrent network model, mainly inspired by \cite{McClelland1995} performs significantly better than traditional FFBP networks. The different experiments are constructed to illuminate different aspects of the pseudo-recurrent network model. Their key confirmed finding is that pseudo-recurrent networks using pseudo-patterns perform significantly better in terms of less catastrophic forgetting, according to both an Ebbinghaus-like savings measure as well as the percentage of explicit recognition of previously learned patterns. Suggesting that the brain may perform a type of pseudo-pattern compression as well as pseudo-recurrent storage of information. Furthermore, they also demonstrate that this new model, in contrast to older models, is prone to the exact opposite of catastrophic forgetting - namely catastrophic remembering.
It should be noted that as the paper shows that catastrophic remembering does occur in special case events where incredibly overlapping inputs are presented, this does not necessarily demonstrate a direct biological implausibility as implied by the authors. A biological input would probably be more multidimensional and noisy, which might play a key role in neural network activity in the event of overlapping inputs. This raises the question about whether this is something that removes the problem of catastrophic remembering. It also raises the question about whether the pseudo-patterns should be generated explicitly, or whether they are generated implicitly by nature, as noise can be said to be inherent in nature. However, from an information theoretic perspective, it is interesting to look at the implications of very dense, low-noise and overlapping inputs using pseudo-patterns, as this is what is dealt with in many of the field's applications. Again when investigating the biological brain, it does appear as if that boggles up certain memories, too. This can be seen by simply thinking of events around the same time or place. If doing so, you might experience that these memories feel fuzzy, and possibly flow over in one another - in other words; overlap. Thus it would be reasonable to state that some boggling up due to overlap is in fact biologically plausible, and possibly part of an efficient computational algorithm for information processing in neural networks. Furthermore, the networks simulated are of such a small scale that they will only be able to generalise to a certain extent due to network capacity. The latter point about scale seems to have been largely ignored by the authors. Therefore it would be interesting to look at the implications of both increasing the complexity as well as the scale of the network. It is also worth noting that the semi-distributedness of this paper's model arises naturally from the pseudo-recurrent neural network, as opposed to in the former papers of \cite{French1992, French1994}. Possibly this mechanism, which acts as an auto-associative memory, also acts as a predictor. That is, in addition to completing incomplete, partial or fuzzy memories and retrieving them, it might provide a mechanism to filling in a story, or even imagining a story, creating it on the go by using the pseudo-recurrent mechanisms. This could suggest that the interleaving of memories in a pseudo-reccurent manner is at the heart of creativity, prediction and not the least; cognition.
\\
\\
\textbf{French, R. M., Ans, B., \& Rousset, S. (2001). Pseudopatterns and dual-network memory models : Advantages and shortcomings. Connectionist Models of Learning, Development and Evolution, 13-22.}

\cite{French2001} address the currently present issues of the dual-network memory architecture, illuminating key issues related to episodic memory, contextualisation, and pseudo-pattern generation and optimisation. In doing this, they conclude that the brain is likely to perform some kind of pseudo-pattern optimisation. Possibly in a stochastic way relative to how well it evaluates its performance and understanding of a currently perceived concept or state. When it comes to episodic memory, the work of \cite{Ans2000} is elaborated on, in which only dissimilar pseudo-inputs were used for consolidation to a neocortical network. Results demonstrated that the model was capable of generalising to and thus learning all patterns (20 patterns, where only 13 were explicitly taught to the neocortical network). This strengthens the view that the hippocampus and neocortex function as a dual-network memory in the mammalian brain. Another aspect that is addressed is contextualisation in the dual-network memory architecture. \cite{Ans2000} demonstrated that their implementation of a dual-network memory model performed better with pseudo-patterns with random initial input rather than when retrieving similar patterns from the neocortical module. This does pose an inconsistency biologically speaking, because it is biologically implausible to retrieve an output representing the activity of the entire neocortex in order to interleave new memories with old, and retrieving similar patterns mostly leads to a failure of convergence. However, as the model is simplified in terms of neocortical modules, the fact that it fails to converge when retrieving similar inputs from the neocortical module may be an implementational and algorithmic issue. Suggesting that in order to have successful contextualisation and thus stronger generalisation, this issue needs to be revised from that perspective. A suggestion includes investigating the possibility of several networks, or at least several layers of processing, directing patterns in a more intricate top-down bottom-up synthesis within the neocortex during consolidation from the hippocampus. Similarly, this could improve and possibly solve the problem of convergence within the hippocampus. Optionally, the hippocampal module itself may need to be revised, implementing slightly different or additional principles to have successful convergence of interleaving emerge. Note that pseudo-pattern generation itself most likely needs to be changed in order for a successful and more directed interleaving to converge. Suggesting that there may in fact be other, or more principles, that play a crucial role in the dual-network synthesis. Summarising; the dual-network memory model offers significant benefits and advances in neural network models, but there seems to be an oversimplification related to pseudo-pattern formation and generation, affecting the integration across similar, yet separate memories.
\\
\\
\textbf{Solbakken, L. J. (2009). Fuzzy Oscillations: a Novel Model for Solving Pattern Segmentation. Institutt for datateknikk og informasjonsvitenskap, NTNU. The Norwegian University of Science and Technology.}

In his master's thesis, \cite{Solbakken2009} demonstrates that oscillations between populations of spiking neurons in an ANN model can synchronise the activity of the network as a whole, as well as its sub-networks. This enables the segmentation of multidimensional data, through modulatory feedback, also largely avoiding a superposition catastrophe. Namely where objects that are to be segmented share many similar features, and therefore a network may fail to segment them into different categories or as different objects. Object recognition with shared features can be performed when populations of neurons learn to recognise features, and those features then represent representations of more abstract objects, for instance a bike or a car (which both have wheels). With slightly richer than average neuronal dynamics, using Izhikevich neurons (\cite{Izhikevich2003}, cited in \cite{Solbakken2009}), \cite{Solbakken2009} attained a simple model that managed to capture the dynamics of successful segmentation of complex scenes with static input. Concluding from the findings that such a model extends traditional ANNs in including temporal information, in which there is a competitive segmentation process that may separate features, also evading a combinatorial explosion due to the model's dynamics. It is interesting to note how these dynamics are made possible by contrasts and/or extensions of more traditional models such as the FFBP ANN. Specifically, it is unclear which information processing capabilities that emerge by introducing synchronisation, and which emerge implicitly through introducing the Izhikevich neuron model. Avoiding the superposition catastrophe bears certain similarities to node sharpening, because reaching a steady state with competing oscillators will cause them to synchronise, effectively making one population "win" - analogously become sharpened. Perhaps oscillations is the true biological implementation of such a mechanism? Furthermore, when it comes to the convergence towards a steady state for a feature that a neural population recognises: This bears a lot of biological resemblance to cognition, and thus it may be attractive to regard it as a biologically plausible mechanism, potentially providing richer dynamics in an effective way. As for the biological plausibility, the resemblance can be described rather intuitively; humans usually do not see all possible parallels of resemblance to an object. The recognition of parts converges, and settles into a steady state. An analogy could be the well known example of an ambiguous image, in which there are two or more recognizable objects, for instance animals - once you have seen one of the figures hidden in it, it more or less excludes the other, and you're very likely to continue seeing the very figure you're currently perceiving. Furthermore, evading a combinatorial growth in embedding steady state dynamics in the network would indeed seem very biologically plausible. Another concept that \cite{Solbakken2009} addresses in his thesis is the binding problem. As illuminated in his thesis, analogously to how water droplets may condense from steam,  there has to be a change which links meaning to activity in a network model, (\cite{Freeman2003}, cited in \cite{Solbakken2009}). It seems as if the findings may suggest a possible coupling in populations of neurons being connected to populations of neurons. It remains obscure, however, how this translates into meaning other than possibly constituting a mechanism for abstraction. Perhaps this would be sufficient, as the mechanism of observing oneself then is inherent in the mechanism of abstraction? In either way, it seems as if oscillatory dynamics has the potential of solving several fundamental information processing problems related to neural networks, including memory and segmentation. Whether synchronicity due to oscillations, which result in rich dynamics, may emerge solely from neuronal and topological variations, or if has to be embedded in a more direct manner, remains unclear. Note that a dynamical topology is likely to be favourable in a system with high-level cognitive behaviour, as this may result in greater plasticity.
\\
\\
\textbf{Maniadakis, M., Trahanias, P., \& Tani, J. (2012). Self-organizing high-order cognitive functions in artificial agents: Implications for possible prefrontal cortex mechanisms. Neural Networks, 33, 76-87.}

\cite{Maniadakis2012} demonstrated the ability of recurrent neural networks (RNNs) to self-organize when being evolved by genetic algorithms. They successfully evolved networks which learned a dynamically changing task, navigating in a simulated physical robot environment. Learning such a complex behaviour is usually associated with higher order cognitive functions, suggesting that the presented model may relate to the workings of the brain, and more specifically the mechanisms of the prefrontal cortex.
Their study was conducted by using the Wisconsin Card Sorting Test, embedded by a betting function, performed by a robot in a control environment. Because of the nature of the problem domain, and the complexity of the RNNs, they divided the experiment into several phases, in order to better investigate the emergence of network properties. Their main findings include that a bottle-neck in the continuous time recurrent neural network architecture was favorable, or even necessary, for the model to attain satisfactory high-level cognitive behaviour. Note that their experiments were limited to very similar environments, thus it would be interesting to study the generalisation in different domains. It is also worth emphasising that the paper differs from others in the field in that it looks upon cognition as embodied in the environment, which most likely results in significant topological impact on the resulting models (due to the genetic algorithm evolving it). It would be interesting to investigate the environmental correlate with the the network topology and dynamics. Both through evolution and environmental impact when using a genetic algorithm.
\\
\\
\textbf{Hattori, M. (2014). A biologically inspired dual-network memory model for reduction of catastrophic forgetting. Neurocomputing, 134, 262-268.}

In this excellent paper, \cite{Hattori2014} presents a novel ANN model and dual-memory architecture, consisting of two modules. Namely a hippocampal as well as a neocortical module, similar to the model of \cite{McClelland1995}. Hattori demonstrates in several experiments that the catastrophic forgetting is reduced to a large extent in the new model, and also that it is superior to the dual-network memory architectures of \cite{Hattori2010}, which which in turn outperformed the more conventional models of \cite{Ans1997}, and \cite{French1997}. However, the model presented in \cite{Hattori2014} is not used to solve complex tasks, as the model is rather heavy in terms of computational complexity (from introducing more complex neuronal dynamics). He further demonstrates that the HPC network is capable of acquiring information rapidly, and also to consolidate this into the neocortical network (when it is extracted successfully in the HPC module).
When it comes to the neuronal models, the hippocampal model contains McCulloch and Pitts neurons, using the Oja rule for learning in connections between the different sub-modules, except for in the CA3 sub-module, where Hebbian learning with forgetting is used.
The fact that mean goodness and perfect recall was worse in the hetero-associative case suggests that a significant amount of plasticity is missing in the model. Making it unable to actually find the correlations and extract the correct patterns as well as for the trivial case of simply remembering the input. This is further supported by the observation that a much higher turnover rate than observed biologically has to be employed for improving the model. As one way of achieving greater plasticity may be to introduce more randomness in searching for patterns, by for instance using a very high neuronal turnover, this suggests that the high turnover rate could be what alleviates the lack of plasticity. Despite allowing for a more flexible search by the model, it might also introduce too much of randomness in the search, not making it sufficiently fine-grained. It would be interesting to see parameter adjustments for the hetero-associative case in the hippocampal module, as this may pose different constraints on the network. Particularly an analysis of the edge of chaos for the CA3-part. Another important aspect would be attempting to temporally extend the model, in an attempt to capture how episodic memory may be constituted in a complementary memory model. Such a synthesis could potentially introduce novel aspects of high-level cognition. Therefore it would be interesting and possibly fruitful to look at variations in neuronal dynamics as well as topologies in future experiments.
\\
\\
\textbf{Tani, J. (2014). Self-Organization and Compositionality in Cognitive Brains : A Neurorobotics Study. Proceedings of the IEEE, 102(4), 586-605.}

In this insightful paper, \cite{Tani2014} further investigates high-level cognition in neural networks, addressing the key concept of compositionality and how this might constitute cognition. Reviewing evidence that the mammalian brain attains complex high-level cognition through a functional hierarchy, he seeks to gain further knowledge about how this may be constituted at the neural level. He introduces two RNN models, and applies each architecture to two different complex tasks, respectively. Both models share the feature of having a type of top-down bottom-up synthesis. In the first architecture, an RNN with a parametric bias (PB) connecting the networks, the top level can be regarded as constantly trying to predict what the lower level is perceiving. If something "unknown" is then perceived, this is learned by a learning mechanism, which works on minimising an error criteria. In the other model, he introduces a multi-network CTRNN architecture, which performs iterative learning on the continuous flow of perceived input. Both models were successfully applied in four different experiments. The main findings include a successful extraction of linguistic properties of sentences and correlated actions and objects with the RNNPB model in the first and second experiment. In the third experiment, the MTRNN successfully attained a functional hierarchy of action primitives, allowing the model to perform complex motor-sensory tasks in a top-down bottom-up synthesis of the higher and lower levels of the MTRNN. A very interesting aspect of the MTRNN is the use of different timescales, with the slower high-level parts of the network enabling this synthesis. Note that this can be regarded as a solution to the symbol grounding problem; the motor-sensory input being a continuous flow of information from the environment, provided by sensory organs, with the symbols and the conscious arising in the synthesis of the functional hierarchy. Tani contemplates of consciousness in a sense arising in the top-down error minimisation for action selection when it comes to motor control. Analogously, such a functional hierarchy could be extrapolated to be valid for any type of sensory data. Consciousness arising in a synthesis, which topologically speaking may be unilateral, and yet a synthesis of hierarchical communication. In such a hypothesized scenario, the question remains how this could be topologically solved. After all, one of the brain's seemingly central properties is its distributedness and completely decentralized workings. Therefore it would be interesting to try to tackle such a problem from an as decentralized perspective as possible.
\\
\\
\textbf{Summary and conclusion}
\\
In investigating a body of research on deep learning, in particular addressing memory, generalisation, and plasticity in neural networks - the problem of catastrophic forgetting, and the symbol grounding problem appears as two of the field's central challenges. One of the main findings of this literature review is the dual-network memory architecture, which was addresses all of the aforementioned issues. The architecture is proposed by \cite{McClelland1995}, and was hypothesised to demonstrate how the brain may implement slow memory consolidation and long-term memory potentiation, constituted by the hippocampus and neocortex as a working memory and long-term memory, respectively. Later research building on this seminal paper includes \cite{French1997, Ans1997, Ans2000, French2001, Hattori2010, Hattori2014}, in which it is demonstrated that such an architecture actually eliminates the problem of catastrophic forgetting to a large extent. However, certain issues of how to implement such a model remains unclear, including:
\begin{itemize}
\item how pseudo-patterns can be employed
\item alternative mechanisms for interleaving
\item how patterns may be learned in the hippocampal module
\item how information might be retrieved from the neocortical module
\end{itemize}
Later work, such as \cite{Hattori2014} demonstrates that chaotic neurons may have a crucial function with respect to consolidation in dual-network memory architectures, as well as enabling a more non-deterministic and plastic behaviour to emerge. It is evident that there are some very interesting phenomena that may emerge from dual-network architectures. Furthermore, \cite{Tani2014} demonstrated that an MTRNN is capable of extracting a functional hierarchy of action primivites by the use of a slower timescale in the higher levels of the spiking neural network. This raises the question of whether a dual-network memory architecture could be combined with MTRNNs, replacing the neocortical module and representing the prefrontal cortex and its connections to other cortical areas such as the motor cortex. In that case, the symbol grounding problem would be addressed in the same way as in \cite{Tani2014}. Suggesting that the way in which the hippocampal and neocortical modules are coupled possibly may change. This contrasts previously suggested models in that input is not directly propagated through the hippocampus, but it is propagated through the neocortex to the hippocampus. Which would address the problem of convergence in the hippocampus as encountered in \cite{Ans1997, Ans2000, French2001}, potentially posing a solution in that the nature of the input to the hippocampal module will be different, as the dynamics of the neocortical module will change fundamentally. It would be interesting to investigate topological implications in such a model, experimenting with how and what parts are connected. One possible solution could be to couple the CA3 part of the HPC with the PFC, with the aim of being able to combine different abstract representations that may converge because of the spiking dynamics of the MTRNN. Such an intertwining could have the potential of capturing temporal sequences in a way that previous dual-network memory architectures has failed to. This is an idea that has been suggested by \cite{Hattori2014}, who proposes that spiking neurons could potentially capture t he underlying principles for episodic memory. As a conclusion, it would be very interesting to embed spiking neurons in a dual-network memory architecture, building upon the work of among others \cite{Yamashita2008, McClelland1995, Hattori2014}. In this thesis our aim is to implement such a model, seeking to attain a more generalisable and powerful ANN model, to illuminate methods for successful integration across memories, and furthermore to investigate the implications of neuronal dynamics and network topology on the network dynamics in the dual-network memory architecture.


\cleardoublepage