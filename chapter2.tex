%===================================== CHAP 2 =================================

\chapter{Literary Review}
\section{Introduction}

Recent advances in deep learning may render several state-of-the-art approaches within other fields of artificial intelligence (AI) such as image classification and natural language processing obsolete, as they have been outperformed by more generally applicable algorithms of deep learning (\cite{LeCun2015, Schmidhuber2014}). These advances are due to both computational as well as algorithmic improvements within the field. New insights into how high-level cognition may be constituted and emerge in neural networks may further advance field's capabilities, possibly beyond what can be achieved only by an increase in computational power. At the very core of such new insights lies the symbol grounding problem. This problem is addressed by several authors such as \cite{Yamashita2008, Tani2014}, who propose solutions to the long standing symbol grounding problem. However, there are still issues present in the models related to generalisation. The problem of generalisation has on the other hand been addressed by other authors such as \cite{McClelland1995}, and more recently \cite{Hattori2014}. In their seminal paper, \cite{McClelland1995} propose a dual-network memory model, hypothesising that the brain solves the problem of long-term memory and memory consolidation by the use of a dual-network memory architecture. Because the body of research, to the best of our knowledge, on the dual-network memory architecture is fairly limited, the goal of this thesis is to further investigate the issues of catastrophic forgetting and generalisation, memory, and high-level cognition in such an architecture. Elucidating high-level abstraction in this architecture could provide key insights for further advances within deep learning, artificial intelligence, neuroscience and psychology. The problem of catastrophic forgetting is of central importance to memory formation in neural networks, and thus also plays a key role in forming abstract memories from different types of memories. We wish to investigate it outside of the domain of traditional topologies, as well as the standard feed-forward back-propagate algorithm. Furthermore, building on the work of \cite{Hattori2014}, we seek to embed an approach such as multiple-timescales recurrent neural networks in a dual-network memory model. The motivation for this stems from seeking to attain an artificial neural network model capable of attaining high-level cognitive behaviour as well as integration across abstract memories.
In order to investigate the body of research on the topic, the databases of Scopus, Web of Science, IEEE, Nature, and arXiv were used to locate references of interest. A process of following networks of citations was employed, particularly by using the paper of \cite{McClelland1995}. Furthermore, as some heavily cited authors appeared, such as Tani and Schmidhuber, their list of publications were used as sources for references, using Google's search engine to find their lists of publications.

\section{Annotated Bibliography}

\textbf{French, R. M. (1992). Semi-distributed Representations and Catastrophic Forgetting in Connectionist Networks. Connection Science, 4(3-4), 365-377.}

\cite{French1992} addresses the problem of catastrophic forgetting \cite{McCloskey1989, Ratcliff1990} in neural networks that are trained using feed-forward back-propagation, and argues that it occurs because of representational overlap. A method alleviating the problem is to make use of a sparse distributed memory (SDM), which works fairly well until the memory is digested. However, once it is digested severe catastrophic forgetting occurs, and old memories are disrupted in addition to that new ones may not be formed. Furthermore, it is not possible to combine different representations as easily due to the sparsity in an SDM, rendering the approach less generalisable. One way of viewing this is that the distributedness segments more tasks because it acts as a regularizer by constraining the state space. However, this simplification may oversimplify the architecture, causing it to lose out on crucial information due to locally constrained pattern formations. Node sharpening, which is the author's proposed solution, locally constrains input patterns to enhance the most prominent features, effectively resulting in sparse representations. This results in less "noise" being propagated throughout the network, the most principal input nodes being in focus, and a significant reduction in catastrophic forgetting. However, this is done at the cost of attaining a less generalisable model, as node sharpening only looks at the \textit{n} most prominent nodes. Furthermore, today's state-of-the-art algorithms employs different transfer functions, network topologies, and learning. This suggests that the paper's claim, being that that the trade-off between catastrophic forgetting and generalisation is inevitable, may not hold today.


\textbf{French, R. M. (1994). Dynamically constraining connectionist networks to produce distributed, orthogonal representations to reduce catastrophic interference. Network, 1111, 00001.}

Building on his former work (\cite{French1992}), \cite{French1994} proposes a model which dynamically sharpens the most relevant input nodes. Once two different outputs has been presented to a standard feed-forward back-propagate (FFBP) network, a context bias is calculated in the hidden layer and propagated back to the input layer. Shortly put, this emphasizes the differences of the distinct categories, focusing on segmenting and orthogonalizing on the most prominent properties of difference in a relative manner. Thus more orthogonal, well distributed patterns are learned.
Although this type of segmentation works well, it is still very similar to the former approach in \cite{French1992}, and suffers from the same trade-off between remembering and generalisation. As in other FFBP networks performing gradient descent in weight space (\cite{Hinton1989}), the algorithm will only succeed to find the most principal components, scaling with how much information the network is able to store (mainly affected by its size). As a consequence, failing to attain a sufficient accuracy for a given task could be due to ignoring the detailed information present in the segmentation process. Furthermore, it may be the case that only finding the most principal correlations in a distribution does not reveal the true nature of it, failing to extract the most precise correlations or properties. This is at the very core of the sensitivity-stability dilemma (\cite{Hebb1949}). One way way of addressing this dilemma is by multi-network systems , which \cite{French1994} suggests in his conclusion. This may produce refined solutions and abstractions and more sophisticated pattern-associations, although seemingly less computationally efficient.


\textbf{McClelland, J. L., McNaughton, B. L., \& O’Reilly, R. C. (1995). Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory. Psychological Review, 102(3), 419-457.}

In this seminal paper, \cite{McClelland1995} propose a memory model of the brain in which the hippocampus is responsible for the consolidation of memories to the neocortex, with the neocortex storing the semantic and episodic memory. The synthesis of recall from the deeper layers of the neocortex and representations in the working memory itself enables contexts to be distinguished or connected. The learning and consolidation to the neocortex is essentially performed in an interleaved fashion; slowly potentiating and instantiating those memories to the cortex. Thus we have a bottom-up and top-down synthesis where recall is combined with novel patterns in the hippocampal module. This raises the question of how such an interconnectedness is constituted both topologically and in terms of local information-processing. Furthermore, the question is whether principles from outside the neocortex and hippocampus need to be extracted and implemented to successfully have this functionality emerge in computational models. Addressing the latter, the proposed model suggests that the hippocampus and neocortex constitute the mechanisms for successful integration across memories, as well as keeping memories fairly intact. The specifics on how these mechanisms are constituted, however, remains obscure or undiscovered.


\textbf{French, R. M. (1997). Pseudo-recurrent Connectionist Networks: An Approach to the “Sensitivity-Stability” Dilemma. Connection Science, 9(4), 353-380.}

A series of experiments that address the sensitivity-stability dilemma (\cite{Hebb1949}) is presented in this paper, in which the authors demonstrate that a pseudo-recurrent network model, mainly inspired by \cite{McClelland1995}, performs significantly better than traditional feed-forwad back-propagate networks. Different experiments are used to illuminate several aspects of the pseudo-recurrent network model. The key finding is that pseudo-recurrent networks using pseudo-patterns perform significantly better in terms of less catastrophic forgetting, suggesting that the brain may perform a type of pseudo-pattern compression as well as pseudo-recurrent storage of information. Another point worth noting is that the networks that are simulated are of such a small scale that they will only be able to generalise to a certain extent due to network capacity, which seems to have been largely ignored by the authors. Therefore it would be interesting to look at the implications of both increasing the complexity as well as the scale of the network. Note that the semi-distributedness of this paper's model arises naturally from the pseudo-recurrent neural network, as opposed to in the former papers of \cite{French1992, French1994}. This may suggest that the mechanism, which acts as an auto-associative memory, may also act as a predictor. In addition to completing incomplete, partial or fuzzy memories and retrieving them, it might therefore also provide a mechanism to filling in a story, or even imagining a story, creating it on the go by using the pseudo-recurrent mechanisms. This could suggest that the interleaving of memories in a pseudo-reccurent manner is at the heart of creativity, prediction and not the least; cognition.


\textbf{French, R. M., Ans, B., \& Rousset, S. (2001). Pseudopatterns and dual-network memory models : Advantages and shortcomings. Connectionist Models of Learning, Development and Evolution, 13-22.}

\cite{French2001} address the currently present issues of the dual-network memory architecture, illuminating key issues related to episodic memory, contextualisation, and pseudo-pattern generation and optimisation. In doing this, they conclude that the brain is likely to perform some kind of pseudo-pattern optimisation. Possibly in a stochastic way relative to how well it evaluates its performance and understanding of a currently perceived concept or state. When it comes to episodic memory, the work of \cite{Ans2000} is elaborated on, in which only dissimilar pseudo-inputs were used for consolidation to a neocortical network. Results demonstrated that the model was capable of generalising to and thus learning all patterns (20 patterns, where only 13 were explicitly taught to the neocortical network). This strengthens the view that the hippocampus and neocortex function as a dual-network memory in the mammalian brain. Another aspect that is addressed is contextualisation in the dual-network memory architecture. \cite{Ans2000} demonstrated that their implementation of a dual-network memory model performed better with pseudo-patterns with random initial input rather than when retrieving similar patterns from the neocortical module. This does pose an inconsistency biologically speaking, because it is biologically implausible to retrieve an output representing the activity of the entire neocortex in order to interleave new memories with old, and retrieving similar patterns mostly leads to a failure of convergence. This suggests that there may in fact be other, or more, principles that play a crucial role in the dual-network memory architecture. Summarising; the dual-network memory model offers significant benefits and advances in neural network models, but there seems to be an oversimplification related to pseudo-pattern formation and generation, affecting the integration across similar, yet separate memories.


\textbf{Yamashita, Y., \& Tani, J. (2008). Emergence of functional hierarchy in a multiple timescale neural network model: a humanoid robot experiment. PLoS Computational Biology, 4(11), e1000220.}

Functional hierarchies of reusable neural patterns of activation are believed to constitute the mechanisms for among other things motor primitives in the brain. Such functional hierarchies have been earlier been realized by the explicit coding of a hierarchical structure in artificial neural networks. In this paper, however, \cite{Yamashita2008} propose a novel model in which such a functional hierarchy self-organizes due to the existence of multiple timescales within the network. Thus, the topological split is in a way transformed to a temporal separation, yet now enabling the coordination and segmentation to occur in a more generalisable manner as the reusable motor primitives are no longer hardwired by topological constraints. Their findings still demonstrate that performance is better with a topology supporting segmentation (with a type of bottle-neck between the networks of neurons that operate on different timescales), though segmentation is possible in both cases due to multiple timescales. These findings suggest that there are both spatial and temporal mechanisms which lead to the emergence of functional hierarchies within neural networks. Training is performed by the use of back-propagation through time, in which the desired output generates an error signal. It would be interesting to see what kind of implications different transfer functions (now a sigmoid transfer function is used) would have. Furthermore, always enabling a level of training could provide for a more dynamically suitable network. In such an event, the mechanisms for propagation would most likely have to be changed.


\textbf{Solbakken, L. J. (2009). Fuzzy Oscillations: a Novel Model for Solving Pattern Segmentation. Institutt for datateknikk og informasjonsvitenskap, NTNU. The Norwegian University of Science and Technology.}

In his master's thesis, \cite{Solbakken2009} demonstrates that oscillations between populations of spiking neurons in an ANN model can synchronise the activity of the network as a whole, as well as its sub-networks. This enables the segmentation of multidimensional data through modulatory feedback, also largely avoiding a superposition catastrophe. Namely where objects that are to be segmented share many similar features, and as a result a network may fail to segment the objects into different categories or to distinguish the objects. Object recognition with shared features can be performed when populations of neurons learn to recognise features, and those features then represent representations of more abstract objects, for instance a bike or a car (which both have wheels). With slightly richer than average neuronal dynamics, using Izhikevich neurons (\cite{Izhikevich2003}, cited in \cite{Solbakken2009}), \cite{Solbakken2009} attained a simple model that managed to capture the dynamics of successful segmentation of complex scenes with static input. From which the authors conclude that such a model extends traditional ANNs in including temporal information, resulting in a competitive segmentation process that may separate features, effectively evading a combinatorial explosion. It is interesting to note how these dynamics are made possible by contrasts and/or extensions of more traditional models such as the FFBP ANN. Specifically, it is unclear which information processing capabilities that emerge by introducing synchronisation, and which emerge by introducing the Izhikevich neuron model. Avoiding the superposition catastrophe bears certain similarities to node sharpening, because reaching a steady state with competing oscillators will cause the populations to synchronise, effectively making one population "win" - or analogously; become sharpened (in focus). Perhaps oscillations is the true biological implementation of such a mechanism. Furthermore, when it comes to the convergence towards a steady state for a feature that a neural population recognises: This bears a lot of biological resemblance to cognition, potentially providing richer dynamics in an effective way. The biological resemblance can be described rather intuitively; consider that humans usually do not see all possible parallels of resemblance to an object. We see a particular object, possibly consisting of particular parts. In other words; the recognition converges, and settles into a steady state. An example could be the well known example of an ambiguous image, in which there are two or more recognizable objects, for instance animals - once you have seen one of the figures hidden in it, the other is more or less not seen, and you're very likely to continue seeing that very figure you perceived in the first place. Another concept that \cite{Solbakken2009} addresses in his thesis is the binding problem. As illuminated in his thesis, analogously to how water droplets may condense from steam,  there has to be a change which links meaning to activity in a network model, (\cite{Freeman2003}, cited in \cite{Solbakken2009}). As further pointed out in the thesis; it seems as if the findings may suggest a possible coupling in populations of neurons being connected to populations of neurons. It remains obscure, however, how this translates into meaning other than possibly constituting a mechanism for abstraction. Nevertheless, oscillatory dynamics may have the potential to solve several fundamental information processing problems related to neural networks, including memory and segmentation.


\textbf{Maniadakis, M., Trahanias, P., \& Tani, J. (2012). Self-organizing high-order cognitive functions in artificial agents: Implications for possible prefrontal cortex mechanisms. Neural Networks, 33, 76-87.}

\cite{Maniadakis2012} demonstrated the ability of recurrent neural networks (RNNs) to self-organize when being evolved by genetic algorithms. They successfully evolved networks which learned a dynamically changing task, navigating in a simulated physical robot environment. Learning such a complex behaviour is usually associated with higher order cognitive functions, suggesting that the presented model may relate to the workings of the brain, and more specifically the mechanisms of the prefrontal cortex.
Their study was conducted by using the Wisconsin Card Sorting Test, embedded by a betting function, performed by a robot in a control environment. Because of the nature of the problem domain, and the complexity of the RNNs, they divided the experiment into several phases, in order to better investigate the emergence of network properties. Their main findings include that a bottle-neck in the continuous time recurrent neural network architecture was favorable, or even necessary, for the model to attain satisfactory high-level cognitive behaviour. Note that their experiments were limited to very similar environments, thus it would be interesting to study the generalisation in different domains. It is also worth emphasising that the paper differs from others in the field in that it looks upon cognition as embodied in the environment, which most likely results in significant topological impact on the resulting models (due to the genetic algorithm evolving it). It would be interesting to investigate the environmental correlate with the the network topology and dynamics. Both through evolution and environmental impact when using a genetic algorithm.


\textbf{Hattori, M. (2014). A biologically inspired dual-network memory model for reduction of catastrophic forgetting. Neurocomputing, 134, 262-268.}

In this excellent paper, \cite{Hattori2014} presents a novel ANN model and dual-memory architecture, consisting of two modules. Namely a hippocampal as well as a neocortical module, similar to the model of \cite{McClelland1995}. Hattori demonstrates in several experiments that the catastrophic forgetting is reduced to a large extent in the new model, and also that it is superior to the dual-network memory architectures of \cite{Hattori2010}, which which in turn outperformed the more conventional models of \cite{Ans1997}, and \cite{French1997}. However, the model presented in \cite{Hattori2014} is not used to solve complex tasks, as the model is rather heavy in terms of computational complexity (from introducing more complex neuronal dynamics). He further demonstrates that the HPC network is capable of acquiring information rapidly, and also to consolidate this into the neocortical network (when it is extracted successfully in the HPC module).
When it comes to the neuronal models, the hippocampal model contains McCulloch and Pitts neurons, using the Oja rule for learning in connections between the different sub-modules, except for in the CA3 sub-module, where Hebbian learning with forgetting is used.
The fact that mean goodness and perfect recall was worse in the hetero-associative case suggests that a significant amount of plasticity is missing in the model. Making it unable to actually find the correlations and extract the correct patterns as well as for the trivial case of simply remembering the input. This is further supported by the observation that a much higher turnover rate than observed biologically has to be employed for improving the model. As one way of achieving greater plasticity may be to introduce more randomness in searching for patterns, by for instance using a very high neuronal turnover, this suggests that the high turnover rate could be what alleviates the lack of plasticity. Despite allowing for a more flexible search by the model, it might also introduce too much of randomness in the search, not making it sufficiently fine-grained. It would be interesting to see parameter adjustments for the hetero-associative case in the hippocampal module, as this may pose different constraints on the network. Particularly an analysis of the edge of chaos for the CA3-part. Another important aspect would be attempting to temporally extend the model, in an attempt to capture how episodic memory may be constituted in a complementary memory model. Such a synthesis could potentially introduce novel aspects of high-level cognition. Therefore it would be interesting and possibly fruitful to look at variations in neuronal dynamics as well as topologies in future experiments.


\textbf{Tani, J. (2014). Self-Organization and Compositionality in Cognitive Brains : A Neurorobotics Study. Proceedings of the IEEE, 102(4), 586-605.}

In this insightful paper, \cite{Tani2014} further investigates high-level cognition in neural networks, addressing the key concept of compositionality and how this might constitute cognition. Reviewing evidence that the mammalian brain attains complex high-level cognition through a functional hierarchy, he seeks to gain further knowledge about how this may be constituted at the neural level. He introduces two RNN models, and applies each architecture to two different complex tasks, respectively. Both models share the feature of having a type of top-down bottom-up synthesis. In the first architecture, an RNN with a parametric bias (PB) connecting the networks, the top level can be regarded as constantly trying to predict what the lower level is perceiving. If something "unknown" is then perceived, this is learned by a learning mechanism, which works on minimising an error criteria. In the other model, he introduces a multi-network CTRNN architecture, which performs iterative learning on the continuous flow of perceived input. Both models were successfully applied in four different experiments. The main findings include a successful extraction of linguistic properties of sentences and correlated actions and objects with the RNNPB model in the first and second experiment. In the third experiment, the MTRNN successfully attained a functional hierarchy of action primitives, allowing the model to perform complex motor-sensory tasks in a top-down bottom-up synthesis of the higher and lower levels of the MTRNN. A very interesting aspect of the MTRNN is the use of different timescales, with the slower high-level parts of the network enabling this synthesis. Note that this can be regarded as a solution to the symbol grounding problem; the motor-sensory input being a continuous flow of information from the environment, provided by sensory organs, with the symbols and the conscious arising in the synthesis of the functional hierarchy. Tani contemplates of consciousness in a sense arising in the top-down error minimisation for action selection when it comes to motor control. Analogously, such a functional hierarchy could be extrapolated to be valid for any type of sensory data. Consciousness arising in a synthesis, which topologically speaking may be unilateral, and yet a synthesis of hierarchical communication. In such a hypothesized scenario, the question remains how this could be topologically solved. After all, one of the brain's seemingly central properties is its distributedness and completely decentralized workings. Therefore it would be interesting to try to tackle such a problem from an as decentralized perspective as possible.


\section{Summary and conclusions}

In investigating a body of research on deep learning, in particular addressing memory, generalisation, and plasticity in neural networks - the problem of catastrophic forgetting, and the symbol grounding problem appears as two of the field's central challenges. One of the main findings of this literature review is the dual-network memory architecture, which was addresses all of the aforementioned issues. The architecture is proposed by \cite{McClelland1995}, and was hypothesised to demonstrate how the brain may implement slow memory consolidation and long-term memory potentiation, constituted by the hippocampus and neocortex as a working memory and long-term memory, respectively. Later research building on this seminal paper includes \cite{French1997, Ans1997, Ans2000, French2001, Hattori2010, Hattori2014}, in which it is demonstrated that such an architecture actually eliminates the problem of catastrophic forgetting to a large extent. However, certain issues of how to implement such a model remains unclear, including:
\begin{itemize}
\item how pseudo-patterns can be employed
\item alternative mechanisms for interleaving
\item how patterns may be learned in the hippocampal module
\item how information might be retrieved from the neocortical module
\end{itemize}
Later work, such as \cite{Hattori2014} demonstrates that chaotic neurons may have a crucial function with respect to consolidation in dual-network memory architectures, as well as enabling a more non-deterministic and plastic behaviour to emerge. It is evident that there are some very interesting phenomena that may emerge from dual-network architectures. Furthermore, \cite{Tani2014} demonstrated that an MTRNN is capable of extracting a functional hierarchy of action primivites by the use of a slower timescale in the higher levels of the spiking neural network. This raises the question of whether a dual-network memory architecture could be combined with MTRNNs, replacing the neocortical module and representing the prefrontal cortex and its connections to other cortical areas such as the motor cortex. In that case, the symbol grounding problem would be addressed in the same way as in \cite{Tani2014}. Suggesting that the way in which the hippocampal and neocortical modules are coupled possibly may change. This contrasts previously suggested models in that input is not directly propagated through the hippocampus, but it is propagated through the neocortex to the hippocampus. Which would address the problem of convergence in the hippocampus as encountered in \cite{Ans1997, Ans2000, French2001}, potentially posing a solution in that the nature of the input to the hippocampal module will be different, as the dynamics of the neocortical module will change fundamentally. It would be interesting to investigate topological implications in such a model, experimenting with how and what parts are connected. One possible solution could be to couple the CA3 part of the HPC with the PFC, with the aim of being able to combine different abstract representations that may converge because of the spiking dynamics of the MTRNN. Such an intertwining could have the potential of capturing temporal sequences in a way that previous dual-network memory architectures has failed to. This is an idea that has been suggested by \cite{Hattori2014}, who proposes that spiking neurons could potentially capture t he underlying principles for episodic memory. As a conclusion, it would be very interesting to embed spiking neurons in a dual-network memory architecture, building upon the work of among others \cite{Yamashita2008, McClelland1995, Hattori2014}. In this thesis our aim is to implement such a model, seeking to attain a more generalisable and powerful ANN model, to illuminate methods for successful integration across memories, and furthermore to investigate the implications of neuronal dynamics and network topology on the network dynamics in the dual-network memory architecture.


\cleardoublepage