%===================================== CHAP 1 =================================

\chapter{Introduction}

In recent years the field of artificial intelligence (AI) has seen a great increase in attention drawn towards it. Both academically speaking, as well as from the general public. Several films from the popular industry have been created about the topic, focusing on its probably unrealistic, yet potentially puzzling moral dilemmas. The reason for the sudden increase of interest in the field is mainly due to its increasing success within applications during the last decade. We have reached a technological point where processing power enables traditional approaches such as simple neural networks using standard feed-forward back-propagation to achieve good results on tasks like classification of data, by among other training techniques performing gradient-descent in weight space. Furthermore, more advanced and computationally demanding approaches have also become tractable, resulting in algorithms that have been able to learn to perform a great deal of complex tasks. Some examples include Google's DeepMind playing Atari 2600 games using deep reinforcement learning (\cite{Mnih2015}), and the self-organization of a functional hierarchy of motor primitives enabling a robot to move and perform speech-recognition using a multiple-timescales recurrent neural network (\cite{Tani2014}). State-of-the-art algorithms have been improved tremendously within the branches of speech-recognition, visual recognition and image classification, object recognition, and biological computing (\cite{LeCun2015}). The common factor for advances within all of these fields is deep learning: Namely when a network-based approach and algorithm employs multiple levels and layers of processing. This thesis focuses on deep neural networks, which have seen a vast amount of new applications during last decade within all of the aforementioned fields of AI.
\\
%\section{Artificial Neural Networks}

An artificial neural network (ANN) is a biologically inspired approach, in which some key principles, believed to constitute some aspects of brain functionality, are implemented. It is a biologically inspired method in that it is very loosely coupled to how biological neurons actually function, as a lot of this process is omitted due to computational efficacy and applicability. If one were to implement most of the knowledge that neuroscience has gathered about neurons in such networks from a molecular perspective, the result would most likely be intractable in terms of applicability to computer scientific problems. Therefore, mathematical approximations are used, which usually aims for having some desired functionality emerge at the macro-level. The main principle constituting neural network functioning is widely recognized to be Hebbian Learning (\cite{Hebb1949}), which can be summarised as "fire together - wire together". In other words, if two neurons are active at the same time, the connection between the two should be strengthened, and conversely; if they do not, the connection should be weakened. This is one of the core foundations for the field of neural networks, with Hebbian Learning having been successfully applied in different forms in ANN implementations for more than half a century.
\\
%\section{Recurrent Neural Networks}

Recurrence in neural networks has been thoroughly investigated, a central aspect being auto-associative memory, first elaborated on by Hopfield (\cite{Hopfield1982}), after whom Hopfield networks are named. \cite{Hopfield1982} showed that in connecting neurons of slightly more advanced nature, namely McCulloch and Pitts neurons in a recursive manner, a type of auto-associative memory would emerge. In this type of network presenting only part of a pattern may lead to automatic pattern completion, depending on how much of a pattern that is presented, and how many patterns that the network has learned. Such auto-associative memory has been shown to be successful for retrieval of memories, i.e. partial pattern completion, for learning a number of patterns up to approximately 15 \% of $N$, being the number of neurons in the network (\cite{Hopfield1982}). Auto-associative memory in Hopfield networks can be regarded as a type of short-term memory, as it will converge towards steady states of previously learned patterns relative to an input pattern that is presented to it.

Another aspect of recurrence is that it enables a network to 'remember' backwards in in time. This works similarly to how auto-associative memory does, with a connection being recurrent either implicitly in that it goes to a parent node in the network, or explicitly in that a node is simply connected to itself. In other words, recurrent neural networks (RNNs) have the capability of learning temporal dependencies. However, traditional RNN architectures still struggle with learning temporal dependencies spanning longer time windows. Therefore, state-of-the-art algorithms within deep learning today employ additional approaches to allow nodes to recall long term dependencies, the approaches being the use of long short-term memory (LSTM) units \cite{Hochreiter1997}, or general recurrent units (GRUs) (\cite{Cho2014}), both essentially implementing the same feature of remembering long term dependencies backward in time. This allows for the use of standard gradient descent based methods in training RNNs whilst still capturing dependencies spanning fairly long temporal intervals.

Lastly, it is worth mentioning that the mammalian brain appears to be of a very recurrent and slightly chaotically connected nature. Indeed, recurrence captures aspects of long- and short-term memory. Insights from neuroscience may therefore provide clues as to how emergent phenomena may be topologically captured in ANNs.
For instance, when regarding the visual cortex as consisting of layers of stacked micro-columns, the V1 area of neurons have a lot of horizontal connections to other columns in the visual cortex, each consisting of six layers. This may enable the currently observed features of different parts of the visual field to affect other parts of the visual cortex. Potentially affecting the convergence of a population of neurons towards other features through modulatory feedback (including the population the firing stems from).
\\
%\section{Catastrophic Interference}

Catastrophic forgetting \cite{McCloskey1989} is a term which describes the phenomena of when an ANN model forgets large parts, or everything that it has previously learned, i.e. it forgets what it has previously managed to remember to such an extent that the performance is equal to that of randomly assigning its weights. Catastrophic interference is a term capturing both catastrophic forgetting, as well as other types of interference, such as when a network model will fails to attain new knowledge. The latter might occur if a model has a certain storage capacity, and it is presented with even more data after its capacity has been exhausted. This might result in the network not only failing to learn new patterns, but also disrupt older learned patterns, such as is the case in a Hopfield network. The stable states of a Hopfield network may be considered as basins of attractions in a three-dimensional space. If there are too many basins of attraction, the behaviour will be unstable, and the state of the network will oscillate chaotically in the entire state space.
When it comes to traditional FFBP ANNs, if training the network in a novel problem domain, the process of gradient descent will adjust the weights according to the new domain only, neglecting all knowledge that was previously attained from the former domain.
It can also be seen that catastrophic interference may occur if the data set that we are training an ANN model on is sufficiently complex. In this case the network may be exhausted, failing to generalise from the data, i.e. the network complexity is not sufficient to extract the desired distributions from a given data set. 
The fact that catastrophic forgetting occurs in an FFBP ANN when it is trained on a novel problem reflects the fact that the network is only a local stochastic extraction of correlations from a probability distribution constituted by a data set.
\\
%\section{The Dual-Network Memory Architecture}

The dual-network memory architecture (\cite{McClelland1995}) is a proposed model for how the brain solves the problem of catastrophic interference, also alleviating catastrophic interference in a proposed ANN model. However, the architecture has not been studied extensively, and still suffers from some issues due to simplification or obscurity in implementation. Furthermore, it is only recently that recurrence in such a model has been studied. \cite{Hattori2014} investigates how trying to capture the chaotic macro-scale behaviour of the CA3 region of the hippocampus affects such a model, and concludes with the model being improved. Furthermore, he concludes that it would be very interesting to investigate possible implications of introducing spiking neurons to such a model and architecture.
\\

%\section{Deep Learning}

Deep learning in neural networks is not a well-defined term. However, it may be regarded as when networks consist of several layers, resulting in a deep neural network.
Traditionally, shallow, but wide networks were used to try and solve problems of increasing complexity.
As computing power increased, and neural networks managed to solve problems of increasing complexity, deep networks were starting to gain attention. However, more traditional ANN approaches still suffered from a lack of plasticity, resulting in different parts of deep networks representing different features, effectively segmenting the network itself in order to segment patterns in a data set. It is important to emphasise that this is problematic when trying to combine different features, or introducing patterns that share many common properties, possibly resulting in oscillations between different segments of the network, or in the worst case catastrophic interference.
That being said, deep networks does have an advantage of an increased capacity, alleviating the aforementioned issue. However, as we introduce recurrence in networks in order to capture temporal information, the capacity of the network is reduced, as some is required for a temporal memory. Furthermore, in order to form more complex abstractions, the network needs to be synchronized as a whole - having sub-networks acting as distinct networks will necessarily fail to form certain abstract patterns. Which is why researching more complex structures capable of such generalisation is a problem of central importance in deep learning today.
\\
%\section{High-level Cognition and the Symbol Grounding Problem}

High-level cognition may be regarded as the more sophisticated behaviour observed within the animal kingdom, primarily associated with intelligence. Language is perhaps the prime example of the most high-level cognitive behaviour exhibited by human beings. Other examples in mammals include learning of motor control from sensory input, different forms of communication, internal mapping of the environment, and emotion.
How different aspects of high-level cognition may emerge in artificial neural networks remains a partly philosophical, and very puzzling problem. Several applications of ANNs have demonstrated the ability of models to perform tasks previously only associated with high-level cognition, such as the learning of and inference of the dynamically changing Wisconsin card sorting test (\cite{Maniadakis2012}), or the successful learning of motor control in robots (\cite{Sugita2005, Yamashita2008, Tani2014}). 
This does not, however, address the aspect of how cognition is coupled to sensory input in neural networks, which is again related to consciousness. An analogy is as outlined by \cite{Freeman2003}; how a gas condenses to a liquid, and how the environment enables this process of phase transitioning.
It is not our aim to answer these questions in the thesis. However, we are inspired by these questions in terms of investigating potential mechanisms for plasticity and memory in neural network models.
\\
%\section{Summary and thesis outline}

Deep learning has led to a tremendous advance in the capabilities of AI within recent years. One particular aspect leading to the advances is the inclusion of temporal information for larger time spans in deep neural networks, which is attained by using LSTM units or GRUs. However, these units are usually very spatially constrained topologically speaking, raising the question of whether such solutions are prone to segmentation issues, where certain features may only be processed in a local neighbourhood, as this is the parts of the network that have learned to segment the given features. This suggests that the plasticity needed to combine memories or patterns in a more general and abstract way may not be not be present. There may be some intricate recurrencies in a network which enable such interactions to a certain extent, but the self-organization of reusable functional hierarchies, such as in \cite{Tani2014}, seems to be something that is not yet captured by general deep learning algorithms. Now, in order to make use of such representations, a top down bottom up synthesis of working memory and long term memory may be needed. This is exactly the basis which is formed by the dual-network memory architecture, and it is our aim in this thesis to build upon such an architecture. 
The main research topic is to study memory and high-level cognition in artificial multi-network memory architectures, investigating possible implications for general state-of-the-art deep learning algorithms.

We believe that a central aspect in continuing to advance the frontier of deep learning is to investigate how high-level level cognitive behaviour and functionality may emerge in ANNs. More specifically, we wish to further investigate the mechanism of reasoning over different memories, in order to attain greater plasticity and generalisation in ANN models. A crucial aspect of being able to combine different memories is simply remembering what has previously been learned. Therefore, the foremost goal of the thesis is to investigate a dual-network memory model such as the one attained by \cite{Hattori2014}. Furthermore, we wish to study different variations of such a model. This includes experiments where other successful and novel approaches within the field are tested, using the dual-network memory model as a framework for studying potential emergent neural mechanisms and network behaviour.
One interesting aspect in such experiments is how recurrency supports specific functionality and emergence within a network. In other words: How recurrence is coupled to both avoiding catastrophic interference and forgetting, and how recurrence adds dimensions to the information processing capabilities of some ANNs.

%\section{Thesis structure}
The structure of this thesis will be as follows. After this introductory chapter, a literary review is presented, consisting of a short introduction, an annotated bibliography of the primary articles of inspiration for the thesis, and a summary and conclusions from the visited body of research. While we are aware that the review of the research body is not complete, we believe the literary review of chapter 2 may suffice as a foundation for constructing further experiments. It is our aim to contribute to the field by providing some novel perspectives on neural network behaviour and memory within multi-network memory architectures and deep learning. In chapter 3 the basic theory forming the platform for the modelling is presented, followed by a short chapter on the technology that we use. Furthermore, we build upon the conclusions drawn in the literary review to establish a platform for the experiments in this thesis. Finally, the results are presented, preceded by a discussion and outline for future research that we wish to conduct.


\cleardoublepage