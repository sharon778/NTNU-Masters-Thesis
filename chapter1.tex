%===================================== CHAP 1 =================================

\chapter{Introduction [Macro level]}\label{chpt:intro}


In recent years, the possible applications of artificial intelligence (AI) have drastically increased. From autonomous self-driving cars \citep{Urmson2009}, to facial recognition systems with super-human performance \citep{Sun2014}, to IBM's Watson performing medical diagnoses \citep{Wagle2013}, to Google's DeepMind playing Atari 2600 games \citep{Mnih2015}. Yet there is a vast amount of potential which has yet to be explored within the field; as IT is becoming increasingly ubiquitous, so does the potential applicability of AI. One of the reasons is that the presence of IT enables harvesting and analysis of data. Two of the common factors for recent advances within AI are increased computational power, and algorithmic improvements. Not only have algorithms performing facial recognition using deep learning become tractable on an average desktop-computer, there has also been an explosion in generated and available data the recent decade (at least to certain companies such as Google and Facebook). In the future, we are likely to see a similar expansion in available data within a vast range of domains due to the Internet of Things, which means that images and visual recognition will be far from the only rich data source and associated algorithm. Note also that a synthesis of data from different domains will most likely become more relevant too in this event, as it has already shown to be key to the performance of systems such as Facebook's excellent visual recognition system \citep{}.
\\

% DL
At the core of several of the aforementioned algorithms lies the sub-field of AI known as deep learning, as briefly touched upon above. Deep learning is a class of algorithms consisting of multiple layers of processing, enabling the extraction of intricate correlations and patterns in data-sets without any prior domain-knowledge or supervision during training. Furthermore, employing convolutional filters as elements of pre-processing, has enabled deep learning algorithms to attain excellent performance in domains such as speech recognition, image classification, and other important tasks such as genomics \citep{LeCun2015}. Furthermore, the convolutional filters, essentially detecting certain features in a data-set, may be trained using deep neural networks themselves, the nets performing the convolution \citep{LeCun2015}. This enables filters to be learned as the data-set is investigated, creating a much more dynamic and generally applicable unsupervised learning algorithm. In other words; the same technique for extracting intricate correlations in a data-set, is used for finding convolutional filters, reducing raw input data to feature vectors which the remaining deep network may process. This leads us to one of the core classes of general learning algorithms that is employed within deep learning; namely the artificial neural network (ANN), which is the overarching focal point of this thesis.
% ANNs
Neural networks are a biologically inspired class of algorithms, which borrows its vocabulary from neuroscience, from which the algorithm is inspired and originates. The processing unit in an artificial neural network (ANN) is namely that of the artificial neuron. This unit may be represented as a single activation value, symbolising a neuron's internal state. In order to process information, vectors of activation values representing the neurons of a layer may be multiplied with matrices representing corresponding weights between the neurons of the current and subsequent layer, i.e. the synapses and their synaptic strengths. This propagates information to the subsequent layer. This process is commonly known as feed-forward in the classical domain of neural networks. Such a network is usually trained using gradient-descent in weight-space by an algorithm such as back-propagation, which back-propagates a generated error signal backwards throughout the network, attempting to minimize the error, most often being a loss function such ass the l1-norm, i.e. the Euclidean distance in space, between two vectors. 
% Connectionism
When ANNs are used in this manner, as simple activation values, weights between the values, and transfer functions between the different layers, the algorithms are quite often solely constructed in order to process data. In a sense the algorithm is constructed for its computer scientific and otherwise domain-applied value, and not to explain some neuroscientific aspect. 
\\

As deep learning algorithms demand high amounts of data in order to converge towards good accuracy and generalisation, the synergy of improved hardware and algorithms have resulted in the sudden explosion of potential applicability. Note that deep learning is primarily an engineering discipline. Meaning that it is more concerned with how to create applicable systems and solutions. Rather than with explaining the biological system from which it originates. I would like to emphasize that it is the synthesis of neuroscience, psychology, and computer science that has given rise to the field of artificial neural networks, and continues to advance it. Exemplified recently by deep learning algorithms where the biologically inspired LSTM unit, and even more recently proposed and simple GRU, have enabled deep networks to capture temporal dependencies in data-sets. Thus a great richness to what correlations and structures that may be captured by this class of general learning algorithm was added. While a unit such as the GRU does not necessarily demonstrate the workings of the biological brain, it does demonstrate that looking at aspects which the biological brain captures, and translating them into algorithmic principles, may significantly improve engineering solutions, having a great computer scientific value and impact. Therefore, attaining further knowledge within any of the aforementioned domains may lead to algorithmic advances within deep learning. 
\\\\


\textbf{Notes}
This is due to both algorithmic as well as computational advances. SLR of the field in the following(?) chapter.

These algorithms, and the field of AI, is largely connectionism. DEFINE: NNs solely based on matrices of weights and values, representing neurons' activation values and synaptic wirings and wiring strengths. This works well for some problems, and has been shown to be able to extract the principal components of a data-set, i.e. doing principal components analysis, by solely performing gradient-descent in weight space, minimizing the loss function of an error criterion (such as the norm of the difference between a target vector output and an acquired vector output).

Recent advances: Deep reinforcement learning. Deep neural networks. Hardware advances (GPUs). Algorithmic improvements using LSTMs or GRUs.

Convolutional nets: Learning feature extraction. More dynamic pre-processing layer.

Connectionism: Purely computer scientific?

Comp. Neuro.: Try and simulate aspects of brain functionality.

Examples of comp. neuro., example from connectionism? (FFBP).

Place model in context.



(Deep learning/connectionism, why it’s interesting and recent advances)
point out weaknesses
nevne convolutional nets
Nevne connectionism og comp. neuro.
one detailed example from comp. neuro. [CONTEXT]
Dual-network memory architecture, sub-field.

Coupling between the above. Justification for computer-scientific value? 
Could be that dual-network models may function in an intertwined that enables emergent phenomena which is previously unattained by single-network approaches. In addition to hypotheses within neuro., etc.

Establish clear topical question(s).
Short thesis outline.

Primary research question: “To study how the brain might implement working and long-term memory using the dual-network memory architecture, and to implement a novel dual-network memory model”


\cleardoublepage