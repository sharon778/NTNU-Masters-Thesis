%===================================== CHAP 1 =================================

\chapter{Introduction [Macro level]}\label{chpt:intro}


In recent years, the possible applications of artificial intelligence (AI) have drastically increased. From autonomous self-driving cars \citep{Urmson2009}, to facial recognition systems with super-human performance \citep{Sun2014}, to IBM's Watson performing medical diagnoses \citep{Wagle2013}, to Google's DeepMind playing Atari 2600 games \citep{Mnih2015}. Yet there is a vast amount of potential which has yet to be explored within the field; as IT is becoming increasingly ubiquitous, so does the potential applicability of AI. One of the reasons is that the presence of IT enables harvesting and analysis of data. Two of the common factors for recent advances within AI are increased computational power, and algorithmic improvements. Not only have algorithms performing facial recognition using deep learning become tractable on an average desktop-computer, there has also been an explosion in generated and available data within recent decades (at least to certain companies such as Google and Facebook). In the future, we are likely to see a similar expansion in available data for the public, within a vast array of domains due to the Internet of Things, which means visual recognition will be far from the only tangible high-performance deep learning algorithm. Note also that a synthesis of data from different domains will most likely become more relevant too in this event, as it has already shown to be key to the performance of systems such as Facebook's excellent visual recognition system \citep{}.
\\

% DL
At the core of several of the aforementioned algorithms lies the sub-field of AI known as deep learning. Deep learning is a class of algorithms where multiple layers of processing are employed, enabling the extraction of intricate correlations and patterns in data-sets without any prior domain-knowledge nor supervision during training. Furthermore, employing convolutional filters as elements of pre-processing has enabled deep learning algorithms to attain excellent performance in domains such as speech recognition, image classification, and genomics \citep{LeCun2015}, the latter displaying the wide applicability of deep learning, as well as the potential benefits it may bring to society. Furthermore, the convolutional filters, essentially performing feature detection in a data-set, may be trained using deep neural networks themselves \citep{LeCun2015}. This enables the nets to learn the filters as the data-set is investigated, creating a much more dynamic and generally applicable unsupervised learning algorithm, although it may require larger amounts of data. In other words; the same technique for extracting intricate correlations in a data-set may in fact be used to find the filters that reduce raw input data to feature vectors, which the remaining deep network may then process. This leads us to one of the core classes of general learning algorithms employed in deep learning; namely the artificial neural network (ANN), which is the overarching focal point of this thesis. I will get back to and pose the main thesis topic, as well as clear topical questions later in the current chapter.
% ANNs
Neural networks is a biologically inspired class of algorithms, borrowing its vocabulary from neuroscience. Going back to 1943, \cite{McCulloch1943} proposed to formalize neural functioning within logical propositions.
However, they could only create a logical calculus based upon the abstract assumptions of the neurological and psychological foundation of the time. Thus hypothesizing that a neural network could be calculated formally was their proposal, assuming amongst other things that neurons could be considered as binary processing units due to the observation that they seemed to fire in an "all-or-none" fashion. This created a framework through which psychological phenomena could be regarded in a reductionist way; as two-valued logic. The way in which neural networks were defined, and thus changed, however, remained obscure. \cite{McCulloch1943} noted that: "With determination of the net, the unknowable object of knowledge, the "thing in itself", ceases to be unknowable".
\footnote{McCulloch, W. S., \& Pitts, W. 1943. 'A Logical Calculus of the Idea Immanent in Nervous Activity', \textit{Bulletin of Mathematical Biophysics}, \textbf{5}: 131.}
Thus describing the long-standing symbol-grounding problem.

Sigmund Freud had in fact already suggested in his 1895 manuscript for 'Project for a Scientific Psychology' that synaptic transmission could promote post-synaptic neural excitation \citep{Kiernan2011}. Despite predicting a variant of Hebbian learning in 1895, more than half a century before Hebb himself, his manuscript was not published until 1950, and as such, the phenomena of synaptic modification resulting from, and relative to the correlation from neural activity amongst neurons, is accredited to Donald O. Hebb \citep{Kiernan2011}.
As \cite{Hebb1949} so eloquently put it: "One cannot logically be a determinist in physics and chemistry and biology, and a mystic in psychology",
\footnote{Hebb, D. O. 1949. \textit{The Organization of Behavior: A Neuropsychological Theory}. New York: JOHN WILEY \& SONS, Inc. Pp. xiii}
he argued that from our current point of view, it does not makes sense to regard brain function as otherwise. He then proceeded from regarding neural functioning as deterministic, to proposing the seminal concept of Hebbian learning, which is widely recognized to be the fundamental mechanism underlying synaptic modification and learning in neural networks. Simply put, Hebbian learning may be summarised as "fire together; wire together".

Summarising, in less than a decade, a formal calculus for neural networks, as well as a neuropsychological theory containing principles for how neurons may perform synaptic modification was proposed. Furthermore, the latter suggests a mechanism for neural network computation, and thus possible mechanisms for memory and learning. From this historical point in time and forward, there has been a continuous synthesis between psychology, neuroscience and computer science. Computer science lending itself to construct models within computational neuroscience, that seek to explain certain neurological aspects of brain functioning, which in turn may explain or be related to aspects of cognition. Conversely, insights from these fields may lend themselves to, and/or inspire computer scientists to create more powerful neural network algorithms performing tasks such as pattern extraction, clustering, classification or segmentation. 

Naturally, this synthesis has spawned different scientific fields. Two of which are known as connectionism and computational neuroscience. While computational neuroscience attempts to tackle problems within neuroscience as explained above, connectionism can be described as a simplistic approach to neural networks, i.e. less biologically plausible neural network models. This does not necessarily mean that researchers seek to use the model only for computer scientific purposes, as one may argue that certain psychological or neurological aspects may be studied without all model aspects being biologically plausible. In fact, until we fully fathom brain functioning neurologically speaking, we cannot hope to create a model which encompasses all biological aspects. Note however that this may not be necessary in order to have certain phenomena emerge from a neural network algorithm. It may be hypothesized that certain principles underlie neural functioning, and thus if simulated algorithmically, the same behaviour may emerge from the algorithm, although implemented quite differently. This is what largely forms the basis for connectionism, where researchers aim to study cognitive phenomena through simplistic computational models.
Quite often, a synthesis between the two aforementioned fields emerges in engineering solutions. This may possibly enable researchers to study both how the brain might implement certain functionality, as well as to study possible algorithmic implications.
\\

\textit{This is the primary motivation for this thesis.}
\\

%\section{Catastrophic Interference}

Catastrophic forgetting \citep{McCloskey1989, Ratcliff1990} is a term which describes the phenomena of when an ANN model forgets large parts, or everything, that it has previously learned. This may occur to such an extent that the performance is equal to that of randomly assigning the network weights. Catastrophic interference is a term capturing both catastrophic forgetting, as well as other types of interference, such as when a network model fails to attain new knowledge. The latter might occur if a model has a certain storage capacity, and it is presented with more training patterns after its capacity has been exhausted. This may result in the network not only failing to learn new patterns, but also disrupting old patterns in attempting to do so. This is the case in Hopfield networks, where the stable states may be considered as basins of attractions in a three-dimensional space. If there are too many basins of attraction, the behaviour will be unstable, and the state of the network will oscillate (at least seemingly) chaotically throughout the entire state space.
When it comes to traditional FFBP ANNs; training the network in a novel problem domain using gradient-descent will adjust the weights according to the new domain only, neglecting all knowledge that may have previously been attained \citep{McCloskey1989, French1999, French2001}.
It can also be seen that catastrophic interference may occur if the data set that we are training an ANN model on is sufficiently complex. In that case the network may be exhausted and fail to generalise from the data, and the network complexity is insufficient for extraction of the desired distributions from the data set. 
The fact that catastrophic forgetting occurs in an FFBP ANN when it is trained in a novel problem domain reflects the fact that the network is only a local stochastic extraction of correlations from a probability distribution constituted by data sets from that domain. Note that recurrence in networks may enable a network to capture more complex dependencies, such as temporal dependencies, but it may also introduce a larger state-space for training algorithms in doing so.
\\
%\section{The Dual-Network Memory Architecture}

\citet{McClelland1995} propose that the brain solves the problem of catastrophic forgetting by a dual-network memory architecture, implemented by the hippocampus and neocortex. However, the body of research within AI on the architecture, is to the best of my knowledge fairly small. Furthermore, proposed implementations suffer from issues related to simplification or obscurity \citep{French1997, French2001, Hattori2010, Hattori2014}. Note also that it is only recently that a more biologically plausible hippocampal network in such a model has been studied. \citet{Hattori2014} investigates how trying to capture the chaotic macro-scale behaviour of the CA3 region of the hippocampus affects its behaviour, and concludes that the model is significantly improved. Furthermore, he states that it would be very interesting to investigate possible implications of introducing spiking neurons in the architecture.
\\

In this thesis, 
the primary research question is: \textit{"To study how the brain might implement working and long-term memory using the dual-network memory architecture, and to implement a novel dual-network memory model"}.
\\
%\section{Summary and thesis outline}

Deep learning has led to a tremendous advance in the capabilities of AI within recent years. One particular aspect leading to the advances is the inclusion of temporal information for larger time spans in deep neural networks, which is attained by using LSTM units or GRUs. However, these units are usually very spatially constrained topologically speaking, raising the question of whether such solutions are prone to segmentation issues where certain features may only be processed in a local neighbourhood. This would suggest that the plasticity needed to combine memories or patterns in a more general and abstract way may not be not yet be present in today's state-of-the-art deep learning algorithms. There may for instance be slightly more intricate network structures which enable abstraction. This is exactly the basis which is formed by the dual-network memory architecture. 
In this thesis the main research topic is to study memory abstraction in artificial dual-network memory architectures, investigating possible implications for general deep learning algorithms. Note that memory is an abstract term used to refer to functions, patterns, or data-set correlations that a network extracts and hopefully learns. More specifically, building upon the model which \cite{Hattori2014} proposes, my aim is to answer the following questions:
\begin{itemize}
\item How does pseudopattern generation enable pattern extraction? With possible parallels to abstraction in neural networks.
\item What are the limitations of pattern extraction in the hippocampal network? And are there any limitations to consolidation to the neocortical network once a pattern has been extracted in the hippocampal module?
\item Will a modified neocortical network using GRUs improve the performance of learning and recall in the network, and thus in the model itself?
\item Is the proposed model less prone to network segmentation than a more conventional FFBP ANN? Where network segmentation effectively is different parts of the network operating as decoupled segments.
\end{itemize}

I believe that a central aspect for advancing the frontier of deep learning is to investigate how high-level level cognitive behaviour and functionality may emerge in ANNs. Investigating the mechanism of reasoning over different memories may potentially provide insights for attaining greater plasticity and generalization in ANN models. This may be seen by considering that a crucial aspect of being able to combine different memories is simply remembering what has previously been learned. Therefore the foremost goal in this thesis is to investigate the dual-network memory architecture which \cite{Hattori2014} proposes in this context.

%\section{Thesis structure}
The structure of this thesis will be as follows: After this introductory chapter a background chapter follows, which contains two fairly short structured literature reviews on the fields on connectionism and computational neuroscience. Furthermore, the chapter lays out a theoretical foundation for neural networks, as well as a more detailed review of catastrophic forgetting. This is followed by a chapter on related work, such as the dual-network memory architecture, as well as on recurrent neural networks. In chapter \ref{chpt:methods}, the methods and implementation of the model is outlined. After which the experiments and results are presented in chapter \ref{chpt:experiments}, naturally followed by a discussion of the thesis findings at the macro level, in chapter \ref{chpt:discussion}. Finally, chapter \ref{chpt:conclusion} concludes the thesis, and outlines what I aspire to pursure in my future work.
\\\\


\textbf{Notes}
\\



point out weaknesses - when introducing the model I am to investigate

Place model in context.
Dual-network memory architecture, sub-field.

Could be that dual-network models may function in an intertwined that enables emergent phenomena which is previously unattained by single-network approaches. In addition to hypotheses within neuro., etc.

Establish clear topical question(s).
Short thesis outline.


NEXT CHPT.:
one detailed example from comp. neuro. [CONTEXT] - [next chpt.]

\cleardoublepage