%===================================== CHAP 1 =================================

\chapter{Introduction [Macro level]}\label{chpt:intro}


In recent years, the possible applications of artificial intelligence (AI) have drastically increased. From autonomous self-driving cars \citep{Urmson2009}, to facial recognition systems with super-human performance \citep{Sun2014}, to IBM's Watson performing medical diagnoses \citep{Wagle2013}, to Google's DeepMind playing Atari 2600 games \citep{Mnih2015}. Yet there is a vast amount of potential which has yet to be explored within the field; as IT is becoming increasingly ubiquitous, so does the potential applicability of AI. One of the reasons is that the presence of IT enables harvesting and analysis of data. Two of the common factors for recent advances within AI are increased computational power, and algorithmic improvements. Not only have algorithms performing facial recognition using deep learning become tractable on an average desktop-computer, there has also been an explosion in generated and available data the recent decade (at least to certain companies such as Google and Facebook). In the future, we are likely to see a similar expansion in available data within a vast range of domains due to the Internet of Things, which means that images and visual recognition will be far from the only rich data source and associated algorithm. Note also that a synthesis of data from different domains will most likely become more relevant too in this event, as it has already shown to be key to the performance of systems such as Facebook's excellent visual recognition system \citep{}.
\\

% DL
At the core of several of the aforementioned algorithms lies the sub-field of AI known as deep learning, as briefly touched upon above. Deep learning is a class of algorithms consisting of multiple layers of processing, enabling the extraction of intricate correlations and patterns in data-sets without any prior domain-knowledge or supervision during training. Furthermore, employing convolutional filters as elements of pre-processing, has enabled deep learning algorithms to attain excellent performance in domains such as speech recognition, image classification, and other important tasks such as genomics \citep{LeCun2015}. Furthermore, the convolutional filters, essentially detecting certain features in a data-set, may be trained using deep neural networks themselves, the nets performing the convolution \citep{LeCun2015}. This enables filters to be learned as the data-set is investigated, creating a much more dynamic and generally applicable unsupervised learning algorithm. In other words; the same technique for extracting intricate correlations in a data-set, is used for finding convolutional filters, reducing raw input data to feature vectors which the remaining deep network may process. This leads us to one of the core classes of general learning algorithms that is employed within deep learning; namely the artificial neural network (ANN), which is the overarching focal point of this thesis.
% ANNs
Neural networks are a biologically inspired class of algorithms, which borrows its vocabulary from neuroscience, from which the algorithm is inspired and originates. The processing unit in an artificial neural network (ANN) is namely that of the artificial neuron. This unit may be represented as a single activation value, symbolising a neuron's internal state. In order to process information, vectors of activation values representing the neurons of a layer may be multiplied with matrices representing corresponding weights between the neurons of the current and subsequent layer, i.e. the synapses and their synaptic strengths. This propagates information to the subsequent layer. This process is commonly known as feed-forward in the classical domain of neural networks. Such a network is usually trained using gradient-descent in weight-space by an algorithm such as back-propagation, which back-propagates a generated error signal backwards throughout the network, attempting to minimize the error, most often being a loss function such ass the l1-norm, i.e. the Euclidean distance in space, between two vectors. 
% Connectionism
When ANNs are used in this manner, as simple activation values, weights between the values, and transfer functions between the different layers, the algorithms are quite often constructed solely in order to process data. In a sense the algorithm is constructed for its computer and domain-specific value, and not to explain an aspect within neuroscience. This branch of learning using neural networks is often referred to as connectionism, which is somewhat synonymous to traditional feed-forward back-propagate (FFBP) neural networks.
Note that deep learning is primarily an engineering discipline. Meaning that it is more concerned with how to create applicable systems and solutions. Rather than with explaining the biological systems from which it originates. I would like to emphasize that despite this, it is the synthesis of neuroscience, psychology, and computer science that has given rise to the field of artificial neural networks and its sub-fields, and continues to advance its application within deep learning. Exemplified only recently by deep learning algorithms where the biologically inspired long short-term memory (LSTM) unit \citep{Hochreiter1997}, and the even more recently proposed perhaps simpler gated recurrent unit (GRU) \citep{Mnih2015}, have enabled deep networks to capture temporal dependencies in data-sets. Adding a fundamental richness to what correlations and structures that may be captured by this class of general learning algorithms, namely long-term temporal dependencies within data. While a unit such as the GRU does not necessarily demonstrate the workings of the biological brain, it does demonstrate that looking at aspects which the biological brain captures, and translating them into algorithmic principles or requirements, may significantly improve engineered solutions and have great computer scientific value and possibly impact. Therefore, attaining further knowledge within any of the aforementioned domains may lead to algorithmic advances within deep learning. 
% -> Computational Neuroscience
At the other end of the scale we have computational neuroscience. Here the basis of Hebbian learning, i.e. "fire together, wire together", is taken not only as a principle which may be mathematically simplified and modelled. Biological plausibility of the underlying principles which results in emergent behaviour and/or phenomena crucial for investigating and understanding brain function. (...)
\\

Quite often, a synthesis between the two aforementioned fields emerges in engineering solutions. This may possibly enable researchers to study both how the brain might implement certain functionality, as well as to either attain a practically applicable solution, or to most commonly also study possible implications for the pure algorithmics of the associated mechanisms.
++ Novel solutions.
\\\\


\textbf{Notes}

This works well for some problems, and has been shown to be able to extract the principal components of a data-set, i.e. doing principal components analysis, by solely performing gradient-descent in weight space, minimizing the loss function of an error criterion (such as the norm of the difference between a target vector output and an acquired vector output).

Recent advances: Deep reinforcement learning. Deep neural networks. Hardware advances (GPUs). Algorithmic improvements using LSTMs or GRUs.

Comp. Neuro.: Try and simulate aspects of brain functionality.

Examples of comp. neuro., example from connectionism? (FFBP).

Place model in context.



(Deep learning/connectionism, why it’s interesting and recent advances)
point out weaknesses
nevne convolutional nets
Nevne connectionism og comp. neuro.
one detailed example from comp. neuro. [CONTEXT]
Dual-network memory architecture, sub-field.

Coupling between the above. Justification for computer-scientific value? 
Could be that dual-network models may function in an intertwined that enables emergent phenomena which is previously unattained by single-network approaches. In addition to hypotheses within neuro., etc.

Establish clear topical question(s).
Short thesis outline.

Primary research question: “To study how the brain might implement working and long-term memory using the dual-network memory architecture, and to implement a novel dual-network memory model”


\cleardoublepage