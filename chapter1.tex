%===================================== CHAP 1 =================================

\chapter{Introduction [Macro level]}\label{chpt:intro}


In recent years, the possible applications of artificial intelligence (AI) have drastically increased. From autonomous self-driving cars \citep{Urmson2009}, to facial recognition systems with super-human performance \citep{Sun2014}, to IBM's Watson performing medical diagnoses \citep{Wagle2013}, to Google's DeepMind playing Atari 2600 games \citep{Mnih2015}. Yet there is a vast amount of potential which has yet to be explored within the field; as IT is becoming increasingly ubiquitous, so does the potential applicability of AI. One of the reasons is that the presence of IT enables harvesting and analysis of data. Two of the common factors for recent advances within AI are increased computational power, and algorithmic improvements. Not only have algorithms performing facial recognition using deep learning become tractable on an average desktop-computer, there has also been an explosion in generated and available data within recent decades (at least to certain companies such as Google and Facebook). In the future, we are likely to see a similar expansion in available data for the public, within a vast array of domains due to the Internet of Things, which means visual recognition will be far from the only tangible high-performance deep learning algorithm. Note also that a synthesis of data from different domains will most likely become more relevant too in this event, as it has already shown to be key to the performance of systems such as Facebook's excellent visual recognition system \citep{}.
\\

% DL
At the core of several of the aforementioned algorithms lies the sub-field of AI known as deep learning. Deep learning is a class of algorithms where multiple layers of processing are employed, enabling the extraction of intricate correlations and patterns in data sets without any prior domain-knowledge nor supervision during training. Furthermore, employing convolutional filters as elements of pre-processing has enabled deep learning algorithms to attain excellent performance in domains such as speech recognition, image classification, and genomics \citep{LeCun2015}, the latter displaying the wide applicability of deep learning, as well as the potential benefits it may bring to society. Furthermore, the convolutional filters, essentially performing feature detection in a data set, may be trained using deep neural networks themselves \citep{LeCun2015}. This enables the nets to learn the filters as a data set is investigated, providing a much more dynamic and generally applicable unsupervised learning algorithm, although it may require larger amounts of data. In other words; the same technique for extracting intricate correlations in a data set may in fact be used to find the filters that reduce raw input data to feature vectors, which the remaining deep network may then process. This leads us to one of the core classes of general learning algorithms employed in deep learning; namely the artificial neural network (ANN), which is the overarching focal point of this thesis. I will get back to and pose the main thesis topic, as well as clear topical questions later in the current chapter.
% ANNs
Neural networks is a biologically inspired class of algorithms, borrowing its vocabulary from neuroscience. Going back to 1943, \cite{McCulloch1943} proposed to formalize neural functioning within logical propositions.
However, they could only create a logical calculus based upon the abstract assumptions of the neurological and psychological basis of the time. Hypothesizing that a neural network could be calculated formally was nevertheless a seminal proposal, assuming amongst other things that neurons could be considered as binary processing units due to the observation that they seemed to fire in an "all-or-none" fashion. This created a framework through which psychological phenomena could be regarded in a reductionist way; through the lens of two-valued logic. The way in which neural networks were defined, and thus changed, however, remained obscure. \cite{McCulloch1943} noted that: "With determination of the net, the unknowable object of knowledge, the "thing in itself", ceases to be unknowable"
\footnote{McCulloch, W. S., \& Pitts, W. 1943. 'A Logical Calculus of the Idea Immanent in Nervous Activity', \textit{Bulletin of Mathematical Biophysics}, \textbf{5}: 131.}
Thus describing the long-standing symbol-grounding problem, which has yet to be elucidated.

In his 1895 manuscript for 'Project for a Scientific Psychology', Sigmund Freud had in fact already suggested that synaptic transmission could promote post-synaptic neural excitation \citep{Kiernan2011}. Despite predicting a variant of Hebbian learning more than half a century before Hebb himself, his manuscript was not published until 1950. Therefore the phenomena of synaptic modification resulting from, and occurring relative to the correlation in neural activity among neurons, is accredited to Donald O. Hebb \citep{Kiernan2011}.
As \cite{Hebb1949} eloquently put it: "One cannot logically be a determinist in physics and chemistry and biology, and a mystic in psychology".
\footnote{Hebb, D. O. 1949. \textit{The Organization of Behavior: A Neuropsychological Theory}. New York: JOHN WILEY \& SONS, Inc. Pp. xiii}
He then regarded neural functioning as deterministic, and proposed the seminal concept of Hebbian learning in his 1949 book 'The Organization of Behavior: A Neuropsychological Theory'. Hebbian learning is widely recognized as the fundamental mechanism underlying synaptic modification and learning in biological neural networks. Simply put, Hebbian learning may be summarised as "fire together; wire together".

Summarising, in less than a decade, a formal calculus for neural network computation, as well as a neuropsychological theory containing principles for how neurons may perform synaptic modification was proposed. Furthermore, the latter suggesting a mechanism for neural network computation, and thus possible mechanisms for memory and learning. From this historical point in time and forward, there has been a continuous synthesis between psychology, neuroscience and computer science with regards to neural computation. Computer science lending itself to construct models within computational neuroscience that seek to explain certain neurological aspects of brain functioning, which in turn may explain or be related to aspects of cognition. Conversely, insights from these fields may lend themselves to, and/or inspire computer scientists in creating more powerful neural network algorithms performing tasks such as pattern extraction, clustering, classification or segmentation. 

Naturally, this synthesis has spawned different scientific fields. Two of which are known as connectionism and computational neuroscience. While computational neuroscience attempts to tackle problems within neuroscience as explained above, connectionism can be described as a simplistic approach to neural networks, i.e. less biologically plausible neural network models. This does not necessarily mean that researchers seek to use the model only for computer scientific purposes, as one may argue that certain psychological or neurological aspects may be studied without all model aspects being biologically plausible. In fact, until we fully fathom brain functioning neurologically speaking, we cannot hope to create a model which will encompass all of its biological aspects. Note however that this may not be a necessity in order to have certain phenomena emerge from a neural network model. It may be hypothesized that certain principles underlie a certain neural functioning, and thus if simulated algorithmically, the same behaviour might emerge in the model. Despite possibly being implemented quite differently. This is what largely forms the basis for connectionism, where researchers aim to study cognitive phenomena through usually simplistic computational models. The main point being that the constraint of biological plausibility is relaxed.
Quite often, a synthesis between the two aforementioned fields emerges in engineering solutions. This may possibly enable researchers to study both how the brain might implement certain functionality, as well as to study possible algorithmic implications.
\\

\textit{This is the primary motivation for the topic which is studied in this thesis.}
\\

%\section{Catastrophic Interference}
Before introducing the model which will be used in this thesis, I would like to introduce the concept of catastrophic forgetting:
Catastrophic forgetting \citep{McCloskey1989, Ratcliff1990} is a term which describes the phenomena of when an ANN model forgets large parts, or everything, that it has previously learned. This may occur to such an extent that the model performance is equal to that of randomly assigning its network weights. Catastrophic interference is a term capturing both catastrophic forgetting, as well as other types of interference, such as when a network model fails to attain new knowledge. The latter may occur if a model is given a number of training patterns that exhausts its storage capacity. This may result in the network not only failing to learn new patterns, but also disrupting old patterns in attempting to learn new. This is the case in Hopfield networks, which I will get back to in chapter \ref{chpt:background}, where stable states may be considered as basins of attractions in a three-dimensional space. If there are too many basins of attraction, the behaviour will be unstable, and the state of the network will oscillate (at least seemingly) chaotically throughout the entire state space.
When it comes to traditional FFBP ANNs; training the network in a novel problem domain using gradient-descent will adjust the weights according to the new domain only, neglecting all knowledge that may have previously been attained \citep{McCloskey1989, French1999, French2001}.
% Move this bit to the DNMA to chpt. 2?
It can also be seen that catastrophic interference may occur if the data set that we are training an ANN model on is sufficiently complex. If the network complexity is insufficient to extract the desired distributions from the data set, gradient-descent is likely not to converge towards a solution.

The fact that catastrophic forgetting occurs in an FFBP ANN when it is trained in a novel problem domain reflects that the network is only a local stochastic extraction of correlations from a probability distribution constituted by a data sets from that domain. Note that recurrence in networks may enable a network to capture more complex dependencies, such as temporal dependencies, but it may also introduce a larger state-space for training algorithms in doing so.
\\

%\section{The Dual-Network Memory Architecture}

\citet{McClelland1995} propose that the brain solves the problem of catastrophic forgetting by a dual-network memory architecture, implemented by the hippocampus and neocortex. However, the body of research within AI on the architecture, is to the best of my knowledge fairly small. Furthermore, proposed implementations suffer from issues related to simplification or obscurity \citep{French1997, French2001, Hattori2010, Hattori2014}. Note also that it is only recently that a more biologically plausible hippocampal network in such a model has been studied. \citet{Hattori2014} investigates how trying to capture the chaotic macro-scale behaviour of the CA3 region of the hippocampus affects its behaviour, and concludes that the model is significantly improved when compared to his former work, which in turn is significantly better than previous implementations of the dual-network memory model. A short abstract definition of the model is that it consists of two networks, where one represents working memory, and the other long-term memory. As patterns are learned by the first network, they are consolidated to the second through the use of pseudopatterns. A pseudopattern remains roughly the same throughout different papers investigating the dual-network memory model, such as \citep{French1997, Ans2000, French2001, Hattori2010, Hattori2014}. Fundamentally, a pseudopattern is a pattern that reflects both the former configuration of the long-term memory network and new patterns that are to be learnt. Pseudopatterns are introduced formally in the following chapter.
Furthermore, \cite{Hattori2014} states that it would be very interesting to investigate possible implications of introducing spiking neurons in the architecture.
\\

In this thesis, 
the primary research question is: \textit{"To study how the brain might implement working and long-term memory using the dual-network memory architecture, and to implement a novel dual-network memory model"}.

I aspire to do this by further investigating the dual-network memory model of \citep{Hattori2014}, and to build upon among others Hattori's work.
\\
%\section{Summary and thesis outline}

Deep learning has led to a tremendous advance in the capabilities of AI within recent years. However, the plasticity needed to combine memories or patterns in a more general and abstract way may not be not yet be present in today's state-of-the-art deep learning algorithms. One observation supporting this is the fact that catastrophic forgetting occurs in FFBP ANNs - and as modern state-of-the-art algorithms are still trained using forms of gradient descent, it is likely that they are prone to the same type of interference, although the storage capacity of today's ANNs within deep learning has drastically increased. 
Note also that there may be slightly more intricate network structures which enable abstraction in itself in other network topologies, as exemplified by authors such as \cite{Tani2014}. This is exactly the basis which is formed by the dual-network memory architecture.
In this thesis the main research topic is to study memory abstraction in the dual-network memory architecture, investigating possible implications for general deep learning algorithms, as well as computational neuroscience. Note that memory is an abstract term used to refer to functions, patterns, or data set-correlations that a network extracts and preferably learns. More specifically, building upon the model which \cite{Hattori2014} proposes, my aim is to answer the following questions:
\begin{itemize}
\item How does pseudopattern generation enable pattern extraction? With possible parallels to abstraction in neural networks.
\item What are the limitations of pattern extraction in the hippocampal network? And are there any limitations to consolidation to the neocortical network once a pattern has been extracted in the hippocampal module?
%\item Will a modified neocortical network using GRUs improve the performance of learning and recall in the network, and thus in the model itself?
\item Is the proposed model less prone to network segmentation than a more conventional FFBP ANN? Where network segmentation effectively is different parts of the network operating as decoupled segments.
\end{itemize}

I believe that a central aspect for advancing the frontier of deep learning is to investigate how high-level level cognitive behaviour and functionality may emerge in ANNs. Investigating the mechanism of reasoning over different memories may potentially provide insights for attaining greater plasticity and generalization in ANN models. This may be seen by considering that a crucial aspect of being able to combine different memories is simply remembering what has previously been learned. Therefore the foremost goal in this thesis is to investigate the dual-network memory architecture in this context.

%\section{Thesis structure}
The structure of the thesis will be as follows: After this introductory chapter a background chapter follows, which contains two fairly short structured literature reviews on the fields on connectionism and computational neuroscience. Furthermore, the chapter lays out a theoretical foundation for neural networks, as well as a more detailed review of catastrophic forgetting. This is followed by a chapter on related work, such as the dual-network memory architecture, as well as on recurrent neural networks. In chapter \ref{chpt:methods}, the methods and implementation of the model is outlined. After which the experiments and results are presented in chapter \ref{chpt:experiments}, naturally followed by a discussion of the thesis findings at the macro level, in chapter \ref{chpt:discussion}. Finally, chapter \ref{chpt:conclusion} concludes the thesis, and outlines what I aspire to pursure in my future work.
\\\\\\\\


\textbf{Notes}
\\

point out weaknesses - when introducing the model I am to investigate

Place model in context.
Dual-network memory architecture, sub-field.

Could be that dual-network models may function in an intertwined that enables emergent phenomena which is previously unattained by single-network approaches. In addition to hypotheses within neuro., etc.

Establish clear topical question(s).
Short thesis outline.


NEXT CHPT.:
one detailed example from comp. neuro. [CONTEXT] - [next chpt.]

\cleardoublepage