%===================================== CHAP 6 =================================

\chapter{Conclusion and future work}\label{chpt:conclusion}
% ============================ section ===============================

Some thoughts from parametrization and debugging of the HPC-net.:
Some sparsity in IN-EC - may be compared to node sharpening
Neuronal turnover (DG) not necessary for single set. However, DG only used during learning. How does this affect the dynamics?
CA3 recurrently connected and seemingly chaotic. Pseudo-chaotic in that it oscillates but forms basins of attraction for learned patterns (because it maps CA3-Output for these patterns). Thus itâ€™s more of a stable state with 


\cleardoublepage