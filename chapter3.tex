%===================================== CHAP 3 =================================

\chapter{Methods and implementation}\label{chpt:methods}

\section{Programming environment}

Theano is a Python library for building high-performance mathematical tools \citep{Bergstra2010}. It lets you write library-specific code which will be analyzed, optimized, and compiled to C or CUDA, enabling execution of efficient bytecode. Furthermore, Theano lets you symbolically define an algorithm in a high-level programming environment. For those familiar with Mathematica, symbolic definition in Theano is fairly similar. In this thesis Python and Theano is used for model implementation, the experiments being outlined in chapter \ref{chpt:experiments}.

Theano is tightly integrated with NumPy, another Python package for scientific computation. Moreover, Theano supports parsing of several NumPy objects into objects which Theano will be able to later use efficiently after its optimization process. Please consult LISA lab's webpage \citep{LISA-lab2015a} for a complete documentation of the framework.
Theano operates on symbolic constructs, termed tensors; general mathematical constructs. In order to define a function, one may write the actual mathematical expression, for instance:

\begin{verbatim}
import theano.tensor as T
import theano

A = T.fmatrix('A')
y = A ** 2
f = theano.function([A], y)
\end{verbatim}

Calling the library function theano.function then analyses the symbolic expression, and constructs executable C or CUDA. See appendix B for a slightly more advanced example using the scan-operator in theano.

When defining symbolic expressions such as functions using Theano, Theano constructs a graph of the provided symbolic expressions, see figure \ref{fig:theano_graph_demo}. This allows for differentiation and manipulation through a syntactic and semantic analysis of the resulting expression graph, optimizing the graph for expression evaluation and graph traversal before code generation. The compiler may then generate optimized code, compiling it according to the provided environmental parameters. This leads to highly efficient C or CUDA executable code.
Note, however, that as the library provides a high-level abstraction for generation of efficient bytecode, this may render debugging somewhat harder. More specifically, the executable code will be further processed from that in pure Python. This means that the programmer may need to predict further how the code will be compiled, making it highly recommendable or necessary to have some previous knowledge within C and/or how the Python-library's compilation process works. A remedy for this is however that Theano supports profiling, providing the programmer with information about what data structures the variables are compiled to, as well information about as their usage. Furthermore, if compiling to a GPU, Theano may output warnings whenever an operation is performed on the CPU.

\begin{figure}
\centering
\includegraphics[width=12cm]{fig/unopt_opt_theano_graph}
\caption{\textbf{Graph manipulation of tensors in Theano} during the optimization and compilation process of an expression such as $y = A^2$. Note that the left-most graph is the graph which has been constructed directly from symbolic differentiation, whereas the right-most hast been optimized before compilation.}
\label{fig:theano_graph_demo}
\end{figure}

In order to use Theano, certain dependencies need to be setup. These are fairly straightforward when it comes to compiling to C-code for CPU-execution. In a preliminary study for this thesis, Theano was setup for use with a GPU on a system with an NVIDIA card, using Ubuntu 14.04 LTS, consulting a guide found on \citep{LISA-lab2015b}. In doing so I found that $k$-WTA requires the dual-network memory model to be synchronized, thus requiring transferring control to the CPU and interpreter, including memory transfer from the GPU to the CPU. Therefore, running the model on the GPU did not provide the basis for a substantial run-time performance gain for the hippocampal model. Therefore I decided to target the CPU, particularly when it comes to the hippocampal module, which may only be executed on the CPU in its current form. Running only the neocortical network on a data-set would, however, be far more efficient using the GPU. In fact, the compiler may target the GPU if the framework for it is setup, and the Theano flags allow a hybrid approach (i.e. no device parameters are set).


% ====================================== IMPLEMENTATION ===========================================
\section{The dual-network memory model}

\subsection{Hippocampal model details}

For the hippocampal network, shared theano variables are instantiated, storing the values of vectors for the activation values, and matrices for the weights between the different layers. Topologically, it remains the same as illustrated previously in figure \ref{fig:hattori_2014_model}. In the hippocampal network, the first step of propagating values throughout the model is to simply multiply the activation values of the first layer with the associated weight matrix, representing its connections, storing the result in the subsequent layer; the EC-layer. After this operation, $k$-WTA is performed. For all layers except for the CA3-layer, these operations are simply performed according to the following equations,

\begin{equation}\label{eq:transfer_function_hpc}
    \textbf{x}_j = tanh (\frac{\textbf{x}_i \textbf{W}_{i,j}}{\epsilon}),
\end{equation}

where $\epsilon$ is a steepness parameter. Succeeding this straightforward propagation between the layers, using a common thresholding function, is setting the activation values in a binary fashion according to the $k$-WTA algorithm;

\begin{equation}
    f(x_i, x_{threshold}) = \begin{cases}
    1, & x_i >= x_{threshold} \\
    0, & otherwise
    \end{cases}
\end{equation}

where $x_{threshold}$ is calculated simply as $x_{threshold} = \frac{x_{k} + x_{k-1}}{2}$, where $x_k$ is the k-th largest activation value in the layer after action potantial potentiation according to equation \ref{eq:transfer_function_hpc}. For pseudocode on the $k$-WTA implementation, please see appendix C.
\\

When it comes to the CA3-layer, information is summed from several layers, after which the equations for chaotic neurons are used to attain the next $\eta$-values, which are finally sent through the thresholding function $tanh$ before $k$-WTA is performed according to the firing rate of the layer. The equations, as outlined in chapter \ref{chpt:existing-models} in equations (\ref{hattori_next_output}, \ref{hattori_eta}, \ref{hattori_zeta}), are here given in vector form;

\begin{equation}\label{eq:eta_zeta_sum}
    \textbf{x}(t+1) = f\{ \vec{\eta}(t+1) + \vec{\zeta}(t+1) \}
\end{equation}

\begin{equation}
    \vec{\eta}(t+1) = k_m \vec{\eta}(t) + \sum_{i} \textbf{W}_{i.j} \textbf{x}_i
\end{equation}

\begin{equation}
    \vec{\zeta}(t+1) = k_r \vec{\zeta}(t) - \alpha \textbf{x}_j(t) + \textbf{a}
\end{equation}

where $k_m$ and $k_r$ are a damping factors of refractoriness, $\textbf{x}_j$ is the input values (i.e. former activation values of the CA3-layer), and $\sum_{i} \textbf{W}_{i.j} \textbf{x}_i$ is the sum of all input values from the preceding layers for $i\in\{ec, dg, ca3\}$, and,

\begin{center}
\begin{math}
    \textbf{x}_i = \textbf{x}_{ec} \textbf{W}_{ec, ca3} + \textbf{x}_{dg} \textbf{W}_{dg, ca3} + \textbf{x}_{ec} \textbf{W}_{ca3, ca3}
\end{math}
\end{center}

Having shared variables store the current values for the eta- and zeta-vectors provides a sufficient basis for iterating through time-steps for the chaotic neurons, given that the surrounding activation value vectors and weight matrices also are instantiated. By using Theano, the above definitions of the equations translates more or less directly to symbolic definitions, thus implementing the model. Please see appendix C for a code excerpt of the hippocampal module, including other code examples, as well as an architectural code overview, and a link to a public git-repository containing the full code.

\begin{figure}
    \centering
    \includegraphics[width=8cm]{fig/kWTA}
    \caption{Illustrating $k$-WTA for an arbitrary network layer of size $n=4$. Note that the figure depicts information flowing to  the same layer after binary thresholding has been performed. Furthermore, the circles, illustrating the neurons, are shadowed relative to their excitation, i.e. activation values, before and after $k$-WTA. This results only in completely excited, or completely depressed (i.e. binary) activation values after $k$-WTA has been performed (as 0 is the lowest value for internal neurons).}
    \label{fig:k_WTA_illustration}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=12cm]{fig/network_propagation}
    \caption{Illustrating \textbf{two network layers and their associated weight matrix}, representing the synapses and the synaptic connection strengths between the two layers. Note that the blue lines symbolise the input from the neurons that produce the next activation values for the first neuron of the second layer. These values are multiplied by the corresponding weights $\textbf{w}$ (squares) and summed (green lines), before finally yielding the first neuron's next activation value by calculating the result of the input sum through the transfer function, $f$.}
    \label{fig:network_layout}
\end{figure}


\subsection{Neocortical model details}

When it comes to the neocortical module, this is implemented essentially as a traditional back-propagation network; having an input and output-layer, and one hidden layer, along with two weight matrices for the connections between the layers. The L2-norm was used as error-function, and diracs delta function was used to chain the error-signal during back-propagation for an efficient execution, using the gradients starting at the output-layer. While the reader may consult Appendix A for the mathematical details and derivation of the equations associated with the traditional feed-forward back-propagation artificial neural network, the essential equations are also provided here, being the following,

\begin{equation}
    \Delta \omega_{i,j} = -\alpha \frac{\partial \textbf{E}}{\partial \omega_{i,j}},
\end{equation}

\noindent
which minimizes the error loss-function \textbf{E} w.r.t. the partial derivative of the weight $\omega_{i,j}$ from neuron $i$ to neuron $j$.
In its full form, the term for the derivative of the error loss-function may be written using the chain rule as,

\begin{equation}
    \frac{\partial \textbf{E}}{\partial u_j}\frac{\partial u_j}{\partial \theta_j} = 
    (\sum_{l \in L}\frac{\textbf{E}}{\partial u_l}\frac{\partial u_l}{\partial \theta_l}) f(\theta_j)(1-f(\theta_j),
\end{equation}

\noindent
where $u_j$ is the activation value of node $j$, and $\theta_j$ is neuron $j$'s total input. Starting at the output layer, one may simplify the equation to,

\begin{center}
\begin{math}
    \frac{\partial \textbf{E}}{\partial u_l} \frac{\partial u_l}{\partial \theta_l} \omega_{j,l} = 
    u_l (u_l - d_l) \omega_{j,l},
\end{math}
\end{center}

which may then be used in the preceding layers after updating the subsequent values, as these will then embed the former terms of the chain into the updates. This allows for a simple implementation and a very efficient algorithm/model. Acquisition of a weight-configuration may also be performed on the GPU. However, this is regarded as unnecessary in the current paradigm, as the data set and number of iterations remain fairly small.


% ========================================== PARAMETERS ================================================

% ========================== Subsection =========================
\subsection{Chaotic patterns and memory consolidation}\label{subsection:hpc-pseudopatterns}

\cite{Ans1997} demonstrate that pseudorehearsal may be used to successfully reduce or eliminate catastrophic forgetting in FFBP ANNs. The mechanism which makes this possible is pseudorehearsal, as previously demonstrated by \cite{Robins1995}. Furthermore, \cite{Ans1997} demonstrate that pseudorehearsal may be performed solely in ANNs. I.e. the entire previous network configuration may be transferred to another network, which may then continuously send patterns (pseudopatterns reflecting the old configuration) to the first network, while the first network also learns novel patterns, thus interleaving the new patterns with old. As FFBP ANNs minimize an error-loss function, typically a distance measure from the attained output to a target output over all patterns in a training set, this results in a weight configuration which minimizes the error for both the old and the new patterns, thus attempting to maintain the new and the old information equally well, the weighting being determined by the number of patterns for each weight configuration when training using gradient-descent.
\\

While it is interesting to note that pseudorehearsal may be used to successfully interleave previously learned patterns with new, it is not my aim to demonstrate this in this thesis.
Storing patterns in a data structure that maintains the previous network configuration, and generating training patterns from this configuration in order to interleave the previous configuration with the new patterns, may also be regarded as storing the information simply in another neural network, such as demonstrated by \cite{French1997}. It remains, however, outside the scope of this thesis to demonstrate that catastrophic forgetting may be reduced to a large extent by pseudorehearsal, as it is fairly well-documented in the literature. 
What I am addressing, is the potential information transfer capabilities inherent in the patterns produced by chaotic recall itself, evaluating the potential emergent qualities of the hippocampal model. Therefore, four different schemes for information transfer and memory consolidation from the hippocampal model to the neocortical network are implemented. Namely:

\begin{enumerate}
    \item Solely using the patterns extracted by chaotic recall as training patterns for the neocortical network.
    \item By employing in addition to the chaotic patterns hippocampal pseudopatterns type I, created in the same manner as neocortical pseudopatterns type I, i.e. by a random input and the corresponding output. This does in other words correspond to adding further chaotically recalled patterns.
    \item By in addition to the chaotic patterns employing hippocampal pseudopatterns type II, which consist of permuted chaotically recalled pattern outputs, and the corresponding hippocampal output after having recurrently fed them through the hippocampal network.
    \item By using chaotically recalled patterns, and both hippocampal pseudopatterns I and II.
\end{enumerate}


\subsection{Model decisions}

During the implementation of the model, I encountered some model aspects that were not clearly stated in the papers on which I base the model; \citep{Hattori2014, Hattori2010}. To proceed with the implementation, certain decisions had to be made.

Asynchronicity may introduce more randomness in searches in algorithms such as in dynamic networks, cellular automata, and Boltzmann machines \citep{Bar-yam1997}. Therefore, having the CA3 neurons update their values asynchronously may enable the layer as an auto-associative network to traverse more of its search space - i.e. it is not as limited in what values that the neurons will take after a certain update/propagation from the preceding layers. This may possibly result in being able to recall more patterns within the hippocampal model, but may on the other hand introduce more noise during learning. Thus the question remains whether the benefit during the search and recall outweighs the possible downsides during learning. Because this extra 'jiggle' is in fact present during learning as well, chances are that having an asynchronous updating scheme is more effective.
The justification of having a synchronized layer updating scheme in the model is that it is a far more efficient implementation - enabling for instance the exploitation of hardware parallelism for matrix operations. Whether asynchronous updating is more effective and biologically plausible is tested and discussed further within the next chapter (\ref{chpt:experiments}).
\\

As for calculating the next activation values of the chaotic neurons in the CA3-layer the paper of \cite{Hattori2014} did not specify whether the vector and matrix products are simply summed, or whether coefficients for some of the weight matrices and synapses are included. Therefore I consulted other references such as \citep{Wakagi2008}, granting insights into, and underlining important topological decisions such as that the inclusion of the DG-layer during learning, which may enable pattern separation. Furthermore, the paper demonstrates and outlines that from the DG-synapses may be magnified (in their model by a factor of 25), such that the connections may impact the CA3-neuronal activation values more heavily.

\cite{Norman2003} implement a complementary learning system containing a hippocampal model, which uses expansion encoding in their DG-layer, arguing that the DG physiologically speaking seems to have the ability to heavily influence the firing patterns of CA3. 
Based upon these papers, a variable weighting of the DG-CA3 pathway is implemented.

Regarding the implementation of eta- and zeta-functions in the CA3-layer, the thresholding is performed after the sum of the products of activation values and weight matrices is calculated. In other words, the hyperbolic tangent transfer function is applied to the sum of the eta- and zeta-functions: 

\begin{center}
\begin{math}
    \textbf{x}_{ca3}(t+1) = tanh(\frac{\eta(t+1) + \zeta(t+1)}{\epsilon})
\end{math}
\end{center}

Lastly, it may be argued that a type of recall may include several iterations of auto-associative recall. Such details, however, are omitted, as average model trends after several iterations may be observed, and the activity of the EC- and DG-layers remain unchanged as long as the input does, given that no neuronal turnover is performed.


% ========================================== SYSTEM ================================================
\section{System layout}

The dual-network memory model is implemented using Python and the library Theano, as previously discussed. In order to instantiate the model, test it, run experiments, and store results; a complete framework within Python is implemented. The core components of the system are the classes wrapping the artificial neural network models, namely; HPC and NeocorticalNetwork. These contain all methods associated with the hippocampal and neocortical networks that are required to perform the algorithmic operations of the dual-network system as outlined in \citep{Hattori2014}. Furthermore, these core classes make use of certain static functions such as displaying a visualization of the current network output during run-time, or writing to a log. These were defined in a Tools-package. In order to verify the functionality of the core modules, a small test suite using unit-testing is implemented, which may be used to automate debugging.
Furthermore, there is a hippocampal module wrapper implementing an abstraction of learning a set of patterns using a hippocampal model object, performing chaotic recall for a given model parametrization and object instance, and the generation of hippocampal pseudopatterns. This wrapper is used in the experimental suite, which implements the experiments that are outlined in the following chapter, (chapter \ref{chpt:experiments}). 

For each experiment that is run, the results are stored in a folder containing the saved data. Furthermore, each distinct experiment is stored in its own distinct folder, where the attained extracted patterns and optionally generated pseudopatterns are stored, both in the form of PNGs, and as binary data which may be imported and used for memory consolidation under different neocortical module schemes. 
All experiments write directly to a log that is located within the saved data folder. This log contains information such as the number of training iterations, the number of extracted patterns (perfectly recalled and spurious), and the goodness of fit for the neocortical module experiments. 
In association with the log and the employed logging formats for the hippocampal and neocorical module experiments, the system implements a parser. This parser is specifically designed to read the corresponding log-files and log-file data, and is connected to a plotting library, which creates figures and plots of the different experiment results. Examples include the average convergence and recall rates by the neuronal turnover rate.

\begin{figure}
    \centering
    \includegraphics[width=8cm]{fig/ExecutionConfiguration.png}
    \caption{Illustrating the \textbf{execution and layout of the system} containing the dual-network memory model and the experimental environment. First; objects are instantiated containing the two networks of the model, then experiments are run from the experimental suite according to the provided run-configuration. This configuration specifies which experiment(s) to run, and with what experimental and model parameters. Note that the experiment makes calls to the HPC-wrapper, and implements calls to the FFBP ANN, i.e. the neocortical network object directly.}
    \label{fig:system_layout}
\end{figure}

In order to generate images of the different layers' activities, simple formulas are used, which generate a rectangular view of a vector of activation values, along with the Python Image Library (PIL). Furthermore, in order to save previous results to disk, simple Python file handling is used to write logs, and cPickle is used to store the binary data of objects, enabling later retrieval and analyses of specific hippocampal models.

For the code of the entire implementation, please see appendix C, which also contains a link to a public git-repository which the reader may clone and run in order to demonstrate the model and experiments him-/herself. Note that a setup-script and short guide is only given for the operating system Ubuntu LTS 14.04.


% \newpage

% \textbf{Notes}

% Where should the focus be? \textit{pseudopattern generation and memory consolidation}

% \textbf{HPC module - high-quality pattern extraction, STM with sufficiently high degradation of old memories to avoid dilution and spurious memories}

% neocortical module - pattern acquisition, acquisition of functional mapping

% Analyzation - see notes.
% \\

% Choices I have made in the implementation that remain unclear in the paper.

% Enforce sparsity through weight updates corresponding only to the winners of $k$-WTA - didn't work.

% (Alternatively: Through initializing synapses only for a given (local) percentage of neurons. - haven't tried, doesn't make sense since the above didn't work?)

% negative weights will necessarily allow for more categorization, and possibly avoiding learning the mean feature vector. However, it reduces perfect recall rates (p. 74) - this may affect especially heteroassociation.

% 49*240 + 240*1600 + 240*480 + 480*1600 + 1600*1600 + 1600*49 = 3 917 360 weights, and 3 905 600 changing weights for every training iteration.

\cleardoublepage