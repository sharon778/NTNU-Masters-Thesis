%===================================== CHAP 3 =================================

\chapter{Basic Theory}

\section{Artificial Neural Networks}

An implementation of the principle of Hebbian learning in a network, using the aforementioned feed-forward back-propagation (FFBP) for learning, can be outlined as follows:
\\
Consider a set of nodes of (artificial) neurons. Each node is connected to some other node(s), together forming a network. Topologically speaking, is is common in traditional approaches to simply construct a given number of layers with each node being connected to one or more nodes in the former and next layer of the network (see figure [cite]), with distinct weights $\omega$ for each connection. In such an approach, the first layer is the input layer, whereas the last layer is the output layer. Data is then presented to the nodes of the input layer, propagated through the hidden layers by using a transfer function and the network weights, before finally arriving at the output nodes, which may represent any functional mapping such as classification, or action selection. Once the input has been propagated throughout the network (fed forward), the obtained output is matched with a desired output, and an error signal is generated (this can be regarded as the difference between the desired and current output). The error signal is then propagated backwards, the weights being updated to adjust for the error. Note that a learning rate constant, $\alpha$, is usually used to restrain the rate of adjustment in order for a solution to converge.
The transfer function is a function of a node's input, transforming its external input to internal activity. In a sense, the transfer function can be regarded as a crude mathematical approximation to a neuron's internal dynamics, usually providing boundaries for a neuron's possible activation values (representing its membrane potential). Weights may be any real valued numbers, but are usually constrained to a certain interval, for instance the interval of [-1, 1]. Some traditional approaches use only binary or tertiary weights, consisting of a set of the weights of -1, 0, or 1.
\\
\\
Mathematically speaking ANNs may be summarised as follows;
\\
a network consists of a set of $N$ nodes. Furthermore, for every node $i\in N$: $i$ may be connected to a node $j \in N$.
\\
For every such connection, there exists a weight, $\omega_{i,j} \in \Re$, the sub-script denoting a connection weight from node $i$ to node $j$.
\\
A transfer function $f$ is a function $f(x)$ of a neuron's input, $x$. A commonly used transfer function is the sigmoid transfer function, simply being 
\begin{equation}
    f(x) = \frac{1}{1+e^{-x}}
\end{equation}
where $x$ is the sum of a neuron's input.
\\
The update of neuronal activation for a node $j$ ca be described as follows:
\\
\begin{equation}
    x_j = \sum_{i\in M} u_i \omega_{i,j}
\end{equation}
\begin{equation}
    u_j = f(x_j)
\end{equation}
where $M$ is the set of all nodes that are connected to neuron $j$, and $u_i$ is the activation value of node $i$.

Consider an example network where the input layer consists of three nodes. A trivial case is where the input nodes are all binary, for instance symbolising a traffic light with three states; either red, yellow, or green. Thus the input to the network would either be {1, 0, 0}, {0, 1, 0}, or {0, 0, 1}, respectively. These nodes could be connected to nodes in a so called hidden layer, a layer which is neither an input nor an output layer of nodes, which again would be connected to an output layer. For this trivial example, consider that these three nodes are directly connected to the output layer, consisting of one node, which corresponds to an action: Walk or wait. It can fairly easily be seen that a successful action selection can be extracted for weights of {1, -1, -1}, if we interpret the output as walk for positive values, and wait for negative values of output. The transfer function is in this case simply a node's value times the weight between a node \textit{i} and a node \textit{j}.


\section{Notes}
Classic RNNs.
\\
The theory of Hattori (2014).
\\
The theory of Tani (2014).
\\
Include Google's now open-sourced framework for deep learning?
\\


\cleardoublepage